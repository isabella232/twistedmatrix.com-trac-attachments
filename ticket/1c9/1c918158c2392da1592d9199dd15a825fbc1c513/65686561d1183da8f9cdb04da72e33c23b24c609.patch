Index: tox.ini
===================================================================
--- tox.ini	(revision 47211)
+++ tox.ini	(working copy)
@@ -21,6 +21,8 @@
      {tests,coverage}: python-subunit
      {tests,coverage}: pycrypto
      {tests,coverage}: appdirs
+     {tests,coverage}: h2
+     {tests,coverage}: priority
 
      py27-{tests,coverage}-posix: pysqlite
      py27-{tests,coverage}: soappy
Index: twisted/python/dist.py
===================================================================
--- twisted/python/dist.py	(revision 47211)
+++ twisted/python/dist.py	(working copy)
@@ -80,14 +80,17 @@
     soap=['soappy'],
     serial=['pyserial'],
     osx=['pyobjc'],
-    windows=['pypiwin32']
+    windows=['pypiwin32'],
+    http2=['h2 >= 2.2.0, < 3.0',
+           'priority >= 1.1.0, < 2.0'],
 )
 
 _PLATFORM_INDEPENDENT = (
     _EXTRA_OPTIONS['tls'] +
     _EXTRA_OPTIONS['conch'] +
     _EXTRA_OPTIONS['soap'] +
-    _EXTRA_OPTIONS['serial']
+    _EXTRA_OPTIONS['serial'] +
+    _EXTRA_OPTIONS['http2']
 )
 
 _EXTRAS_REQUIRE = {
@@ -96,6 +99,7 @@
     'conch': _EXTRA_OPTIONS['conch'],
     'soap': _EXTRA_OPTIONS['soap'],
     'serial': _EXTRA_OPTIONS['serial'],
+    'http2': _EXTRA_OPTIONS['http2'],
     'all_non_platform': _PLATFORM_INDEPENDENT,
     'osx_platform': (
         _EXTRA_OPTIONS['osx'] + _PLATFORM_INDEPENDENT
Index: twisted/python/dist3.py
===================================================================
--- twisted/python/dist3.py	(revision 47211)
+++ twisted/python/dist3.py	(working copy)
@@ -253,6 +253,7 @@
     "twisted.web.demo",
     "twisted.web.error",
     "twisted.web.guard",
+    "twisted.web.http2",
     "twisted.web.http_headers",
     "twisted.web.proxy",
     "twisted.web.resource",
@@ -425,6 +426,7 @@
     "twisted.web.test.test_error",
     # The downloadPage tests weren't ported:
     "twisted.web.test.test_http",
+    "twisted.web.test.test_http2",
     "twisted.web.test.test_flatten",
     "twisted.web.test.test_http_headers",
     "twisted.web.test.test_httpauth",
Index: twisted/python/test/test_dist.py
===================================================================
--- twisted/python/test/test_dist.py	(revision 47211)
+++ twisted/python/test/test_dist.py	(working copy)
@@ -93,6 +93,7 @@
         self.assertIn('all_non_platform', _EXTRAS_REQUIRE)
         self.assertIn('osx_platform', _EXTRAS_REQUIRE)
         self.assertIn('windows_platform', _EXTRAS_REQUIRE)
+        self.assertIn('http2', _EXTRAS_REQUIRE)
 
 
     def test_extrasRequiresDevDeps(self):
@@ -156,6 +157,16 @@
         )
 
 
+    def test_extrasRequiresHttp2Deps(self):
+        """
+        L{_EXTRAS_REQUIRE}'s C{http2} extra contains setuptools requirements
+        for the packages required to make Twisted HTTP/2 support work.
+        """
+        deps = _EXTRAS_REQUIRE['http2']
+        self.assertIn('h2 >= 2.2.0, < 3.0', deps)
+        self.assertIn('priority >= 1.1.0, < 2.0', deps)
+
+
     def test_extrasRequiresAllNonPlatformDeps(self):
         """
         L{_EXTRAS_REQUIRE}'s C{all_non_platform} extra contains setuptools
@@ -172,6 +183,8 @@
         self.assertIn('soappy', deps)
         self.assertIn('pyserial', deps)
         self.assertIn('appdirs >= 1.4.0', deps)
+        self.assertIn('h2 >= 2.2.0, < 3.0', deps)
+        self.assertIn('priority >= 1.1.0, < 2.0', deps)
 
 
     def test_extrasRequiresOsxPlatformDeps(self):
@@ -189,6 +202,8 @@
         self.assertIn('cryptography >= 0.9.1', deps)
         self.assertIn('soappy', deps)
         self.assertIn('pyserial', deps)
+        self.assertIn('h2 >= 2.2.0, < 3.0', deps)
+        self.assertIn('priority >= 1.1.0, < 2.0', deps)
         self.assertIn('pyobjc', deps)
 
 
@@ -207,6 +222,8 @@
         self.assertIn('cryptography >= 0.9.1', deps)
         self.assertIn('soappy', deps)
         self.assertIn('pyserial', deps)
+        self.assertIn('h2 >= 2.2.0, < 3.0', deps)
+        self.assertIn('priority >= 1.1.0, < 2.0', deps)
         self.assertIn('pypiwin32', deps)
 
 
Index: twisted/web/error.py
===================================================================
--- twisted/web/error.py	(revision 47211)
+++ twisted/web/error.py	(working copy)
@@ -385,3 +385,11 @@
 
     def __str__(self):
         return repr(self)
+
+
+
+class UnsupportedSpecialHeader(Exception):
+    """
+    A HTTP/2 request was received that contained a HTTP/2 pseudo-header field
+    that is not recognised by Twisted.
+    """
Index: twisted/web/http.py
===================================================================
--- twisted/web/http.py	(revision 47211)
+++ twisted/web/http.py	(working copy)
@@ -104,7 +104,12 @@
 from twisted.web.iweb import IRequest, IAccessLogFormatter
 from twisted.web.http_headers import Headers
 
-H2_ENABLED = False
+try:
+    from twisted.web.http2 import H2Connection
+    H2_ENABLED = True
+except ImportError:
+    H2Connection = None
+    H2_ENABLED = False
 
 from twisted.web._responses import (
     SWITCHING,
@@ -951,7 +956,8 @@
             self._transport.write(b"0\r\n\r\n")
 
         # log request
-        if hasattr(self._channel, "factory"):
+        if (hasattr(self._channel, "factory") and
+            self._channel.factory is not None):
             self._channel.factory.log(self)
 
         self.finished = 1
@@ -2255,9 +2261,13 @@
 
     @ivar _site: A reference to the creating L{twisted.web.server.Site} object.
     @type _site: L{twisted.web.server.Site}
+
+    @ivar _factory: A reference to the creating L{HTTPFactory} object.
+    @type _factory: L{HTTPFactory}
     """
     _negotiatedProtocol = None
     _requestFactory = Request
+    _factory = None
     _site = None
 
 
@@ -2274,6 +2284,7 @@
         """
         @see: L{HTTPChannel.factory}
         """
+        self._factory = value
         self._channel.factory = value
 
 
@@ -2316,6 +2327,12 @@
 
             if negotiatedProtocol == b'h2':
                 assert H2_ENABLED, "Cannot negotiate HTTP/2 without support."
+                transport = self._channel.transport
+                self._channel = H2Connection()
+                self._channel.requestFactory = self._requestFactory
+                self._channel.site = self._site
+                self._channel.factory = self._factory
+                self._channel.makeConnection(transport)
             else:
                 # Only HTTP/2 and HTTP/1.1 are supported right now.
                 assert negotiatedProtocol == b'http/1.1', \
Index: twisted/web/http2.py
===================================================================
--- twisted/web/http2.py	(revision 0)
+++ twisted/web/http2.py	(working copy)
@@ -0,0 +1,1072 @@
+# -*- test-case-name: twisted.web.test.test_http2 -*-
+# Copyright (c) Twisted Matrix Laboratories.
+# See LICENSE for details.
+
+"""
+HTTP2 Implementation
+
+This is the basic server-side protocol implementation used by the Twisted
+Web server for HTTP2.  This functionality is intended to be combined with the
+HTTP/1.1 and HTTP/1.0 functionality in twisted.web.http to provide complete
+protocol support for HTTP-type protocols.
+"""
+
+from __future__ import absolute_import, division
+
+import io
+import warnings
+import sys
+
+from collections import deque
+
+from zope.interface import implementer
+
+import priority
+import h2.connection
+import h2.events
+import h2.exceptions
+
+from twisted.internet.defer import Deferred, inlineCallbacks
+from twisted.internet.interfaces import (
+    IProtocol, ITransport, IConsumer, IPushProducer
+)
+from twisted.internet.protocol import Protocol
+from twisted.internet.task import LoopingCall
+from twisted.protocols.tls import _PullToPush
+
+
+_END_STREAM_SENTINEL = object()
+
+
+# Python versions 2.7.3 and older don't have a memoryview object that plays
+# well with the struct module, which h2 needs. On those versions, just refuse
+# to import.
+if sys.version_info < (2, 7, 4):
+    warnings.warn(
+        "HTTP/2 cannot be enabled because this version of Python %s is too "
+        "old, and does not fully support memoryview objects.",
+        warnings.UserWarning,
+        stacklevel=2,
+    )
+    raise ImportError("HTTP/2 not supported on this Python version.")
+
+
+
+@implementer(IProtocol, IPushProducer)
+class H2Connection(Protocol):
+    """
+    A class representing a single HTTP/2 connection.
+
+    This implementation of IProtocol works hand in hand with H2Stream. This is
+    because we have the requirement to register multiple producers for a single
+    HTTP/2 connection, one for each stream. The standard Twisted interfaces
+    don't really allow for this, so instead there's a custom interface between
+    the two objects that allows them to work hand-in-hand here.
+
+    @ivar conn: The HTTP/2 connection state machine.
+    @type conn: C{h2.connection.H2Connection}
+
+    @ivar streams: A mapping of stream IDs to L{H2Stream} objects, used to call
+        specific methods on streams when events occur.
+    @type streams: C{dict}, mapping C{int} stream IDs to L{H2Stream} objects.
+
+    @ivar priority: A HTTP/2 priority tree used to ensure that responses are
+        prioritised appropriately.
+    @type priority: L{priority.PriorityTree}
+
+    @ivar _consumerBlocked: A flag tracking whether or not the IConsumer that
+        is consuming this data has asked us to stop producing.
+    @type _consumerBlocked: C{bool}
+
+    @ivar _sendingDeferred: A deferred used to restart the data-sending loop
+        when more response data has been produced. Will not be present if there
+        is outstanding data still to send.
+    @type _consumerBlocked: A L{twisted.internet.defer.Deferred}, or C{None}
+
+    @ivar _outboundStreamQueues: A map of stream IDs to queues, used to store
+        data blocks that are yet to be sent on the connection. These are used
+        both to handle producers that do not respect IConsumer but also to
+        allow priority to multiplex data appropriately.
+    @type _outboundStreamQueues: A C{dict} mapping C{int} stream IDs to
+        C{collections.deque} queues, which contain either C{bytes} objects or
+        L{_END_STREAM_SENTINEL}.
+
+    @ivar _sender: A handle to the data-sending loop, allowing it to be
+        terminated if needed.
+    @type _sender: L{twisted.internet.task.LoopingCall}
+    """
+    factory = None
+    site = None
+
+    def __init__(self):
+        self.conn = h2.connection.H2Connection(client_side=False)
+        self.streams = {}
+
+        self.priority = priority.PriorityTree()
+        self._consumerBlocked = None
+        self._sendingDeferred = None
+        self._outboundStreamQueues = {}
+        self._streamCleanupCallbacks = {}
+
+        # Start the data sending function.
+        self._sender = LoopingCall(self._sendPrioritisedData)
+        self._sender.start(interval=0)
+
+
+    # Implementation of IProtocol
+    def connectionMade(self):
+        """
+        Called by the reactor when a connection is received. May also be called
+        by the GenericHTTPChannel during upgrade to HTTP/2.
+        """
+        self.conn.initiate_connection()
+        self.transport.write(self.conn.data_to_send())
+
+
+    def dataReceived(self, data):
+        """
+        Called whenever a chunk of data is received from the transport.
+
+        @param data: The data received from the transport.
+        @type data: C{bytes}
+        """
+        try:
+            events = self.conn.receive_data(data)
+        except h2.exceptions.ProtocolError:
+            # A remote protocol error terminates the connection.
+            dataToSend = self.conn.data_to_send()
+            self.transport.write(dataToSend)
+            self.transport.loseConnection()
+            self.connectionLost("Protocol error from peer.")
+            return
+
+        for event in events:
+            # TODO: Consider replacing with dictionary-dispatch.
+            if isinstance(event, h2.events.RequestReceived):
+                self._requestReceived(event)
+            elif isinstance(event, h2.events.DataReceived):
+                self._requestDataReceived(event)
+            elif isinstance(event, h2.events.StreamEnded):
+                self._requestEnded(event)
+            elif isinstance(event, h2.events.StreamReset):
+                self._requestAborted(event)
+            elif isinstance(event, h2.events.WindowUpdated):
+                self._handleWindowUpdate(event)
+            elif isinstance(event, h2.events.PriorityUpdated):
+                self._handlePriorityUpdate(event)
+            elif isinstance(event, h2.events.ConnectionTerminated):
+                self.transport.loseConnection()
+                self.connectionLost("Shutdown by remote peer")
+
+        dataToSend = self.conn.data_to_send()
+        if dataToSend:
+            self.transport.write(dataToSend)
+
+
+    def connectionLost(self, reason):
+        """
+        Called when the transport connection is lost.
+
+        Informs all outstanding response handlers that the connection has been
+        lost, and cleans up all internal state.
+        """
+        try:
+            self._sender.stop()
+        except Exception:
+            pass
+
+        for stream in self.streams.values():
+            stream.connectionLost(reason)
+
+        for streamID in list(self.streams.keys()):
+            self._requestDone(streamID)
+
+
+    # Implementation of IPushProducer
+    #
+    # Here's how we handle IPushProducer. We have multiple outstanding
+    # H2Streams. Each of these exposes an IConsumer interface to the response
+    # handler that allows it to push data into the H2Stream. The H2Stream then
+    # writes the data into the H2Connection object.
+    #
+    # The H2Connection needs to manage these writes to account for:
+    #
+    # - flow control
+    # - priority
+    #
+    # We manage each of these in different ways.
+    #
+    # For flow control, we simply use the equivalent of the IPushProducer
+    # interface. We simply tell the H2Stream: "Hey, you can't send any data
+    # right now, sorry!". When that stream becomes unblocked, we free it up
+    # again. This allows the H2Stream to propagate this backpressure up the
+    # chain.
+    #
+    # For priority, we need to keep a backlog of data frames that we can send,
+    # and interleave them appropriately. This backlog is most sensibly kept in
+    # the H2Connection object itself. We keep one queue per stream, which is
+    # where the writes go, and then we have a loop that manages popping these
+    # streams off in priority order.
+    #
+    # Logically then, we go as follows:
+    #
+    # 1. Stream calls writeDataToStream(). This causes a DataFrame to be placed
+    #    on the queue for that stream. It also informs the priority
+    #    implementation that this stream is unblocked.
+    # 2. The _sendPrioritisedData() function spins in a tight loop. Each
+    #    iteration it asks the priority implementation which stream should send
+    #    next, and pops a data frame off that stream's queue. If, after sending
+    #    that frame, there is no data left on that stream's queue, the function
+    #    informs the priority implementation that the stream is blocked.
+    #
+    # If all streams are blocked, or if there are no outstanding streams, the
+    # _sendPrioritisedData function waits to be awoken when more data is ready
+    # to send.
+    #
+    # Note that all of this only applies to *data*. Headers and other control
+    # frames deliberately skip this processing as they are not subject to flow
+    # control or priority constraints.
+    def stopProducing(self):
+        """
+        Stop producing data.
+
+        This tells the H2Connection that its consumer has died, so it must stop
+        producing data for good.
+        """
+        self.connectionLost("stopProducing")
+
+
+    def pauseProducing(self):
+        """
+        Pause producing data.
+
+        Tells the H2Connection that it has produced too much data to process
+        for the time being, and to stop until resumeProducing() is called.
+        """
+        self._consumerBlocked = Deferred()
+
+
+    def resumeProducing(self):
+        """
+        Resume producing data.
+
+        This tells the H2Connection to re-add itself to the main loop and
+        produce more data for the consumer.
+        """
+        if self._consumerBlocked is not None:
+            self._consumerBlocked.callback(None)
+            self._consumerBlocked = None
+
+
+    @inlineCallbacks
+    def _sendPrioritisedData(self):
+        """
+        The data sending loop. Must be used within L{LoopingCall}.
+
+        This function sends data on streams according to the rules of HTTP/2
+        priority. It ensures that the data from each stream is interleved
+        according to the priority signalled by the client, making sure that the
+        connection is used with maximal efficiency.
+
+        This function will execute if data is available: if all data is
+        exhausted, the function will place a deferred onto the C{H2Connection}
+        object and wait until it is called to resume executing.
+        """
+        stream = None
+
+        while stream is None:
+            try:
+                stream = next(self.priority)
+            except priority.DeadlockError:
+                # All streams are currently blocked or not progressing. Wait
+                # until a new one becomes available.
+                assert self._sendingDeferred is None
+                self._sendingDeferred = Deferred()
+                yield self._sendingDeferred
+                self._sendingDeferred = None
+                continue
+
+        # Wait behind the transport.
+        if self._consumerBlocked is not None:
+            yield self._consumerBlocked
+
+        remainingWindow = self.conn.local_flow_control_window(stream)
+        frameData = self._outboundStreamQueues[stream].popleft()
+        maxFrameSize = min(self.conn.max_outbound_frame_size, remainingWindow)
+
+        if frameData is _END_STREAM_SENTINEL:
+            # There's no error handling here even though this can throw
+            # ProtocolError because we really shouldn't encounter this problem.
+            # If we do, that's a nasty bug.
+            self.conn.end_stream(stream)
+            self.transport.write(self.conn.data_to_send())
+
+            # Clean up the stream
+            self._requestDone(stream)
+        else:
+            # Respect the max frame size.
+            if len(frameData) > maxFrameSize:
+                excessData = frameData[maxFrameSize:]
+                frameData = frameData[:maxFrameSize]
+                self._outboundStreamQueues[stream].appendleft(excessData)
+
+            # There's deliberately no error handling here, because this just
+            # absolutely should not happen.
+            self.conn.send_data(stream, frameData)
+            self.transport.write(self.conn.data_to_send())
+
+            # If there's no data left, this stream is now blocked.
+            if not self._outboundStreamQueues[stream]:
+                self.priority.block(stream)
+
+            # Also, if the stream's flow control window is exhausted, tell it
+            # to stop.
+            if self.remainingOutboundWindow(stream) <= 0:
+                self.streams[stream].flowControlBlocked()
+
+
+    # Internal functions.
+    def _requestReceived(self, event):
+        """
+        Internal handler for when a request has been received.
+
+        @param event: The Hyper-h2 event that encodes information about the
+            received request.
+        @type event: L{h2.events.RequestReceived}
+        """
+        stream = H2Stream(
+            event.stream_id, self, event.headers, self.requestFactory
+        )
+        stream.site = self.site
+        stream.factory = self.factory
+        self.streams[event.stream_id] = stream
+        self._streamCleanupCallbacks[event.stream_id] = Deferred()
+        self._outboundStreamQueues[event.stream_id] = deque()
+
+        # Add the stream to the priority tree but immediately block it.
+        try:
+            self.priority.insert_stream(event.stream_id)
+        except priority.DuplicateStreamError:
+            # Stream already in the tree. This can happen if we received a
+            # PRIORITY frame before a HEADERS frame. Just move on: we set the
+            # stream up properly in _handlePriorityUpdate.
+            pass
+        else:
+            self.priority.block(event.stream_id)
+
+
+    def _requestDataReceived(self, event):
+        """
+        Internal handler for when a chunk of data is received for a given
+        request.
+
+        @param event: The Hyper-h2 event that encodes information about the
+            received data.
+        @type event: L{h2.events.DataReceived}
+        """
+        stream = self.streams[event.stream_id]
+        stream.receiveDataChunk(event.data, event.flow_controlled_length)
+
+
+    def _requestEnded(self, event):
+        """
+        Internal handler for when a request is complete, and we expect no
+        further data for that request.
+
+        @param event: The Hyper-h2 event that encodes information about the
+            completed stream.
+        @type event: L{h2.events.StreamEnded}
+        """
+        stream = self.streams[event.stream_id]
+        stream.requestComplete()
+
+
+    def _requestAborted(self, event):
+        """
+        Internal handler for when a request is aborted by a remote peer.
+
+        @param event: The Hyper-h2 event that encodes information about the
+            reset stream.
+        @type event: L{h2.events.StreamReset}
+        """
+        stream = self.streams[event.stream_id]
+        stream.connectionLost("Stream reset")
+        self._requestDone(event.stream_id)
+
+
+    def _handlePriorityUpdate(self, event):
+        """
+        Internal handler for when a stream priority is updated.
+
+        @param event: The Hyper-h2 event that encodes information about the
+            stream reprioritization.
+        @type event: L{h2.events.PriorityUpdate}
+        """
+        try:
+            self.priority.reprioritize(
+                stream_id=event.stream_id,
+                depends_on=event.depends_on or None,
+                weight=event.weight,
+                exclusive=event.exclusive,
+            )
+        except priority.MissingStreamError:
+            # A PRIORITY frame arrived before the HEADERS frame that would
+            # trigger us to insert the stream into the tree. That's fine: we
+            # can create the stream here and mark it as blocked.
+            self.priority.insert_stream(
+                stream_id=event.stream_id,
+                depends_on=event.depends_on or None,
+                weight=event.weight,
+                exclusive=event.exclusive,
+            )
+            self.priority.block(event.stream_id)
+
+
+    def writeHeaders(self, version, code, reason, headers, streamID):
+        """
+        Called by C{Request} objects to write a complete set of HTTP headers to
+        a stream.
+
+        @param version: The HTTP version in use. Unused in HTTP/2.
+        @type version: C{bytes}
+
+        @param code: The HTTP status code to write.
+        @type code: C{bytes}
+
+        @param reason: The HTTP reason phrase to write. Unused in HTTP/2.
+        @type reason: C{bytes}
+
+        @param headers: The headers to write to the stream.
+        @type headers: L{twisted.web.http_headers.Headers}
+
+        @param streamID: The ID of the stream to write the headers to.
+        @type streamID: C{int}
+        """
+        headers.insert(0, (b':status', code))
+        self.conn.send_headers(streamID, headers)
+        self.transport.write(self.conn.data_to_send())
+
+
+    def writeDataToStream(self, streamID, data):
+        """
+        May be called by L{H2Stream} objects to write response data to a given
+        stream. Writes a single data frame.
+
+        @param streamID: The ID of the stream to write the data to.
+        @type streamID: C{int}
+
+        @param data: The data chunk to write to the stream.
+        @type data: C{bytes}
+        """
+        self._outboundStreamQueues[streamID].append(data)
+
+        # There's obviously no point unblocking this stream and the sending
+        # loop if the data can't actually be sent, so confirm that there's
+        # some room to send data.
+        if self.conn.local_flow_control_window(streamID) > 0:
+            self.priority.unblock(streamID)
+            if self._sendingDeferred is not None:
+                self._sendingDeferred.callback(streamID)
+                self._sendingDeferred = None
+
+        if self.remainingOutboundWindow(streamID) <= 0:
+            self.streams[streamID].flowControlBlocked()
+
+
+    def endRequest(self, streamID):
+        """
+        Called by L{H2Stream} objects to signal completion of a response.
+
+        @param streamID: The ID of the stream to write the data to.
+        @type streamID: C{int}
+        """
+        self._outboundStreamQueues[streamID].append(_END_STREAM_SENTINEL)
+        self.priority.unblock(streamID)
+        if self._sendingDeferred is not None:
+            self._sendingDeferred.callback(streamID)
+            self._sendingDeferred = None
+
+
+    def abortRequest(self, streamID):
+        """
+        Called by L{H2Stream} objects to request early termination of a stream.
+        This emits a RstStream frame and then removes all stream state.
+
+        @param streamID: The ID of the stream to write the data to.
+        @type streamID: C{int}
+        """
+        self.conn.reset_stream(streamID)
+        self.transport.write(self.conn.data_to_send())
+        self._requestDone(streamID)
+
+
+    def _requestDone(self, streamID):
+        """
+        Called internally by the data sending loop to clean up state that was
+        being used for the stream. Called when the stream is complete.
+
+        @param streamID: The ID of the stream to clean up state for.
+        @type streamID: C{int}
+        """
+        del self._outboundStreamQueues[streamID]
+        self.priority.remove_stream(streamID)
+        del self.streams[streamID]
+        cleanupCallback = self._streamCleanupCallbacks.pop(streamID)
+        cleanupCallback.callback(streamID)
+
+
+    def remainingOutboundWindow(self, streamID):
+        """
+        Called to determine how much room is left in the send window for a
+        given stream. Allows us to handle blocking and unblocking producers.
+
+        @param streamID: The ID of the stream whose flow control window we'll
+            check.
+        @type streamID: C{int}
+
+        @return: The amount of room remaining in the send window for the given
+            stream, including the data queued to be sent.
+        @rtype: C{int}
+        """
+        # TODO: This involves a fair bit of looping and computation for
+        # something that is called a lot. Consider caching values somewhere.
+        windowSize = self.conn.local_flow_control_window(streamID)
+        sendQueue = self._outboundStreamQueues[streamID]
+        alreadyConsumed = sum(
+            len(chunk) for chunk in sendQueue
+            if chunk is not _END_STREAM_SENTINEL
+        )
+
+        return windowSize - alreadyConsumed
+
+
+    def _handleWindowUpdate(self, event):
+        """
+        Manage flow control windows.
+
+        Streams that are blocked on flow control will register themselves with
+        the connection. This will fire deferreds that wake those streams up and
+        allow them to continue processing.
+
+        @param event: The Hyper-h2 event that encodes information about the
+            flow control window change.
+        @type event: L{h2.events.WindowUpdated}
+        """
+        streamID = event.stream_id
+
+        if streamID:
+            # Update applies only to a specific stream. If we don't have the
+            # stream, that's ok: just ignore it.
+            if self._outboundStreamQueues.get(streamID):
+                self.priority.unblock(streamID)
+
+            try:
+                self.streams[streamID].windowUpdated()
+            except KeyError:
+                pass
+        else:
+            # Update strictly applies to all streams.
+            for stream in self.streams.values():
+                stream.windowUpdated()
+
+                # If we still have data to send for this stream, unblock it.
+                if self._outboundStreamQueues.get(stream.streamID):
+                    self.priority.unblock(stream.streamID)
+
+
+    def getPeer(self):
+        """
+        Get the remote address of this connection.
+
+        Treat this method with caution.  It is the unfortunate result of the
+        CGI and Jabber standards, but should not be considered reliable for
+        the usual host of reasons; port forwarding, proxying, firewalls, IP
+        masquerading, etc.
+
+        @return: An L{IAddress} provider.
+        """
+        return self.transport.getPeer()
+
+
+    def getHost(self):
+        """
+        Similar to getPeer, but returns an address describing this side of the
+        connection.
+
+        @return: An L{IAddress} provider.
+        """
+        return self.transport.getHost()
+
+
+    def openStreamWindow(self, streamID, increment):
+        """
+        Open the stream window by a given increment.
+
+        @param streamID: The ID of the stream whose window needs to be opened.
+        @type streamID: C{int}
+
+        @param increment: The amount by which the stream window must be
+        incremented.
+        @type increment: C{int}
+        """
+        # TODO: Consider whether we want some kind of consolidating logic here.
+        self.conn.increment_flow_control_window(increment, stream_id=streamID)
+        self.conn.increment_flow_control_window(increment, stream_id=None)
+        self.transport.write(self.conn.data_to_send())
+
+
+    def _send100Continue(self, streamID):
+        """
+        Sends a 100 Continue response, used to signal to clients that further
+        processing will be performed.
+
+        @param streamID: The ID of the stream that needs the 100 Continue
+        response
+        @type streamID: C{int}
+        """
+        headers = [(b':status', b'100')]
+        self.conn.send_headers(headers=headers, stream_id=streamID)
+        self.transport.write(self.conn.data_to_send())
+
+
+    def _respondToBadRequestAndDisconnect(self, streamID):
+        """
+        This is a quick and dirty way of responding to bad requests.
+
+        As described by HTTP standard we should be patient and accept the
+        whole request from the client before sending a polite bad request
+        response, even in the case when clients send tons of data.
+
+        Unlike in the HTTP/1.1 case, this does not actually disconnect the
+        underlying transport: there's no need. This instead just sends a 400
+        response and terminates the stream.
+
+        @param streamID: The ID of the stream that needs the 100 Continue
+        response
+        @type streamID: C{int}
+        """
+        headers = [(b':status', '400')]
+        self.conn.send_headers(
+            headers=headers,
+            stream_id=streamID,
+            end_stream=True
+        )
+        self.transport.write(self.conn.data_to_send())
+
+        stream = self.streams[streamID]
+        stream.connectionLost("Stream reset")
+        self._requestDone(streamID)
+
+
+
+@implementer(ITransport, IConsumer, IPushProducer)
+class H2Stream(object):
+    """
+    A class representing a single HTTP/2 stream.
+
+    This class works hand-in-hand with H2Connection. It acts to provide an
+    implementation of ITransport, IConsumer, and IProducer that work for a
+    single HTTP/2 connection, while tightly cleaving to the interface provided
+    by those interfaces. It does this by having a tight coupling to
+    H2Connection, which allows associating many of the functions of ITransport,
+    IConsumer, and IProducer to objects on a stream-specific level.
+
+    @ivar streamID: The numerical stream ID that this object corresponds to.
+    @type streamID: C{int}
+
+    @ivar producing: Whether this stream is currently allowed to produce data
+        to its consumer.
+    @type producing: C{bool}
+
+    @ivar command: The HTTP verb used on the request.
+    @type command: C{unicode}
+
+    @ivar path: The HTTP path used on the request.
+    @type path: C{unicode}
+
+    @ivar producer: The object producing the response, if any.
+    @type producer: L{IProducer}
+
+    @ivar _producerProducing: Whether the producer stored in producer is
+        currently producing data.
+    @type _producerProducing: C{bool}
+
+    @ivar _inboundDataBuffer: Any data that has been received from the network
+        but has not yet been received by the consumer.
+    @type _inboundDataBuffer: A L{collections.deque} containing C{bytes}
+
+    @ivar _conn: A reference to the connection this stream belongs to.
+    @type _conn: L{H2Connection}
+
+    @ivar _request: A request object that this stream corresponds to.
+    @type _request: L{twisted.web.iweb.IRequest}
+
+    @ivar _buffer: A buffer containing data produced by the producer that could
+        not be sent on the network at this time.
+    @type _buffer: L{io.BytesIO}
+    """
+    def __init__(self, streamID, connection, headers, requestFactory):
+        self.streamID = streamID
+        self.producing = True
+        self.command = None
+        self.path = None
+        self.producer = None
+        self._producerProducing = False
+        self._hasStreamingProducer = None
+        self._inboundDataBuffer = deque()
+        self._conn = connection
+        self._request = requestFactory(self, queued=False)
+        self._buffer = io.BytesIO()
+
+        self._convertHeaders(headers)
+
+
+    def _convertHeaders(self, headers):
+        """
+        This method converts the HTTP/2 header set into something that looks
+        like HTTP/1.1. In particular, it strips the 'special' headers and adds
+        a Host: header.
+
+        @param headers: The HTTP/2 header set.
+        @type headers: A C{list} of C{tuple}s of header name and header value,
+            both as C{unicode}.
+        """
+        gotLength = False
+
+        for header in headers:
+            if not header[0].startswith(u':'):
+                gotLength = (
+                    _addHeaderToRequest(self._request, header) or gotLength
+                )
+            elif header[0] == u':method':
+                self.command = header[1].encode('utf-8')
+            elif header[0] == u':path':
+                self.path = header[1].encode('utf-8')
+            elif header[0] == u':authority':
+                # This is essentially the Host: header from HTTP/1.1
+                _addHeaderToRequest(self._request, (u'host', header[1]))
+
+        if not gotLength:
+            self._request.gotLength(None)
+
+        self._request.parseCookies()
+        expectContinue = self._request.requestHeaders.getRawHeaders(b'expect')
+        if expectContinue and expectContinue[0].lower() == b'100-continue':
+            self._request._send100Continue()
+
+
+    # Methods called by the H2Connection
+    def receiveDataChunk(self, data, flowControlledLength):
+        """
+        Called when the connection has received a chunk of data from the
+        underlying transport. If the stream has been registered with a
+        consumer, and is currently able to push data, immediately passes it
+        through. Otherwise, buffers the chunk until we can start producing.
+
+        @param data: The chunk of data that was received.
+        @type data: C{bytes}
+
+        @param flowControlledLength: The total flow controlled length of this
+            chunk, which is used when we want to re-open the window. May be
+            different to C{len(data)}.
+        @type flowControlledLength: C{int}
+        """
+        if not self.producing:
+            # Buffer data.
+            self._inboundDataBuffer.append((data, flowControlledLength))
+        else:
+            self._request.handleContentChunk(data)
+            self._conn.openStreamWindow(self.streamID, flowControlledLength)
+
+
+    def requestComplete(self):
+        """
+        Called by the L{H2Connection} when the all data for a request has been
+        received. Currently, with the legacy Request object, just calls
+        requestReceived unless the producer wants us to be quiet.
+        """
+        if self.producing:
+            self._request.requestReceived(self.command, self.path, b'HTTP/2')
+        else:
+            self._inboundDataBuffer.append((_END_STREAM_SENTINEL, None))
+
+
+    def connectionLost(self, reason):
+        """
+        Called by the L{H2Connection} when a connection is lost or a stream is
+        reset.
+
+        @param reason: The reason the connection was lost.
+        @type reason: C{str}
+        """
+        self._request.connectionLost(reason)
+
+
+    def windowUpdated(self):
+        """
+        Called by the L{H2Connection} when this stream's flow control window
+        has been opened.
+        """
+        # If we don't have a producer, we have no-one to tell.
+        if not self.producer:
+            return
+
+        # If we're not blocked on flow control, we don't care.
+        if self._producerProducing:
+            return
+
+        # We check whether the stream's flow control window is actually above
+        # 0, and then, if a producer is registered and we still have space in
+        # the window, we unblock it.
+        remainingWindow = self._conn.remainingOutboundWindow(self.streamID)
+        if not remainingWindow > 0:
+            return
+
+        # We have a producer and space in the window, so that producer can
+        # start producing again!
+        self._producerProducing = True
+        self.producer.resumeProducing()
+
+
+    def flowControlBlocked(self):
+        """
+        Called by the L{H2Connection} when this stream's flow control window
+        has been exhausted.
+        """
+        if not self.producer:
+            return
+
+        if self._producerProducing:
+            self.producer.pauseProducing()
+            self._producerProducing = False
+
+
+    # Methods called by the consumer (usually an IRequest).
+    def writeHeaders(self, version, code, reason, headers):
+        """
+        Called by the consumer to write headers to the stream.
+
+        @param version: The HTTP version.
+        @type version: C{str}
+
+        @param code: The status code.
+        @type code: C{int}
+
+        @param reason: The reason phrase. Ignored in HTTP/2.
+        @type reason: C{str}
+
+        @param headers: The HTTP response headers.
+        @type: Any iterable of two-tuples of C{bytes}, representing header
+            names and header values.
+        """
+        self._conn.writeHeaders(version, code, reason, headers, self.streamID)
+
+
+    def requestDone(self, request):
+        """
+        Called by a consumer to clean up whatever permanent state is in use.
+
+        @param request: The request calling the method.
+        @type request: L{twisted.web.iweb.IRequest}
+        """
+        self._conn.endRequest(self.streamID)
+
+
+    def _send100Continue(self):
+        """
+        Sends a 100 Continue response, used to signal to clients that further
+        processing will be performed.
+        """
+        self._conn._send100Continue(self.streamID)
+
+
+    def _respondToBadRequestAndDisconnect(self):
+        """
+        This is a quick and dirty way of responding to bad requests.
+
+        As described by HTTP standard we should be patient and accept the
+        whole request from the client before sending a polite bad request
+        response, even in the case when clients send tons of data.
+
+        Unlike in the HTTP/1.1 case, this does not actually disconnect the
+        underlying transport: there's no need. This instead just sends a 400
+        response and terminates the stream.
+        """
+        self._conn._respondToBadRequestAndDisconnect(self.streamID)
+
+
+    # Implementation: ITransport
+    def write(self, data):
+        """
+        Write a single chunk of data into a data frame.
+
+        @param data: The data chunk to send.
+        @type data: C{bytes}
+        """
+        self._conn.writeDataToStream(self.streamID, data)
+        return
+
+
+    def writeSequence(self, iovec):
+        """
+        Write a sequence of chunks of data into data frames.
+
+        @param iovec: A sequence of chunks to send.
+        @type iovec: An iterable of C{bytes} chunks.
+        """
+        for chunk in iovec:
+            self.write(chunk)
+
+
+    def loseConnection(self):
+        """
+        Close the connection after writing all pending data.
+        """
+        self._conn.endRequest(self.streamID)
+
+
+    def abortConnection(self):
+        """
+        Forcefully abort the connection by sending a RstStream frame.
+        """
+        self._conn.abortRequest(self.streamID)
+
+
+    def getPeer(self):
+        """
+        Get information about the peer.
+        """
+        self._conn.getPeer()
+
+
+    def getHost(self):
+        """
+        Similar to getPeer, but for this side of the connection.
+        """
+        self._conn.getHost()
+
+
+    # Implementation: IConsumer
+    def registerProducer(self, producer, streaming):
+        """
+        Register to receive data from a producer.
+
+        This sets self to be a consumer for a producer.  When this object runs
+        out of data (as when a send(2) call on a socket succeeds in moving the
+        last data from a userspace buffer into a kernelspace buffer), it will
+        ask the producer to resumeProducing().
+
+        For L{IPullProducer} providers, C{resumeProducing} will be called once
+        each time data is required.
+
+        For L{IPushProducer} providers, C{pauseProducing} will be called
+        whenever the write buffer fills up and C{resumeProducing} will only be
+        called when it empties.
+
+        @param producer: The producer to register.
+        @type producer: L{IProducer} provider
+
+        @param streaming: C{True} if C{producer} provides L{IPushProducer},
+        C{False} if C{producer} provides L{IPullProducer}.
+        @type streaming: C{bool}
+
+        @raise RuntimeError: If a producer is already registered.
+
+        @return: C{None}
+        """
+        if self.producer:
+            raise ValueError(
+                "registering producer %s before previous one (%s) was "
+                "unregistered" % (producer, self.producer))
+
+        if not streaming:
+            self.hasStreamingProducer = False
+            producer = _PullToPush(producer, self)
+            producer.startStreaming()
+        else:
+            self.hasStreamingProducer = True
+
+        self.producer = producer
+        self._producerProducing = True
+
+
+    def unregisterProducer(self):
+        """
+        @see L{IConsumer.unregisterProducer}
+        """
+        # When the producer is unregistered, we're done.
+        if self.producer is not None and not self.hasStreamingProducer:
+            self.producer.stopStreaming()
+
+        self._producerProducing = False
+        self.producer = None
+        self.hasStreamingProducer = None
+
+
+    # Implementation: IPushProducer
+    def stopProducing(self):
+        """
+        @see L{IProducer.stopProducing}
+        """
+        self.producing = False
+        self.abortConnection()
+
+
+    def pauseProducing(self):
+        """
+        @see L{IPushProducer.pauseProducing}
+        """
+        self.producing = False
+
+
+    def resumeProducing(self):
+        """
+        @see L{IPushProducer.resumeProducing}
+        """
+        self.producing = True
+        consumedLength = 0
+
+        while self.producing and self._inboundDataBuffer:
+            # Allow for pauseProducing to be called in response to a call to
+            # resumeProducing.
+            chunk, flowControlledLength = self._inboundDataBuffer.popleft()
+
+            if chunk is _END_STREAM_SENTINEL:
+                self.requestComplete()
+            else:
+                consumedLength += flowControlledLength
+                self._request.handleContentChunk(chunk)
+
+        self._conn.openStreamWindow(self.streamID, consumedLength)
+
+
+
+def _addHeaderToRequest(request, header):
+    """
+    Add a header tuple to a request header object.
+
+    @param request: The request to add the header tuple to.
+    @type request: L{twisted.web.http.Request}
+
+    @param header: The header tuple to add to the request.
+    @type header: A L{tuple} with two elements, the header name and header
+        value, both as L{bytes}.
+
+    @return: If the header being added was the C{Content-Length} header.
+    @rtype: L{bool}
+    """
+    requestHeaders = request.requestHeaders
+    name, value = header
+    name, value = name.encode('utf-8'), value.encode('utf-8')
+    values = requestHeaders.getRawHeaders(name)
+
+    if values is not None:
+        values.append(value)
+    else:
+        requestHeaders.setRawHeaders(name, [value])
+
+    if name == b'content-length':
+        request.gotLength(int(value))
+        return True
+
+    return False
Index: twisted/web/test/test_http.py
===================================================================
--- twisted/web/test/test_http.py	(revision 47211)
+++ twisted/web/test/test_http.py	(working copy)
@@ -299,19 +299,33 @@
         self.assertEqual(negotiatedProtocol, b'http/1.1')
 
 
-    def test_http2(self):
+    def test_http2_present(self):
         """
-        If the transport reports that HTTP/2 is negotiated, that's what's
-        negotiated. Currently HTTP/2 is unsupported, so this raises an
-        AssertionError.
+        If the transport reports that HTTP/2 is negotiated and HTTP/2 is
+        present, that's what's negotiated.
         """
         b = StringTransport()
         b.negotiatedProtocol = b'h2'
+        negotiatedProtocol = self._negotiatedProtocolForTransportInstance(b)
+        self.assertEqual(negotiatedProtocol, b'h2')
+    if not http.H2_ENABLED:
+        test_http2_present.skip = "HTTP/2 support not present"
+
+
+    def test_http2_absent(self):
+        """
+        If the transport reports that HTTP/2 is negotiated and HTTP/2 is not
+        present, an error is encountered.
+        """
+        b = StringTransport()
+        b.negotiatedProtocol = b'h2'
         self.assertRaises(
             AssertionError,
             self._negotiatedProtocolForTransportInstance,
             b,
         )
+    if http.H2_ENABLED:
+        test_http2_absent.skip = "HTTP/2 support present"
 
 
     def test_unknownProtocol(self):
Index: twisted/web/test/test_http2.py
===================================================================
--- twisted/web/test/test_http2.py	(revision 0)
+++ twisted/web/test/test_http2.py	(working copy)
@@ -0,0 +1,1743 @@
+# Copyright (c) Twisted Matrix Laboratories.
+# See LICENSE for details.
+
+"""
+Test HTTP/2 support.
+"""
+
+from __future__ import absolute_import, division
+
+import itertools
+import json
+
+from twisted.internet import defer
+from twisted.protocols.test.test_tls import NonStreamingProducer
+from twisted.python.compat import iterbytes
+from twisted.test.proto_helpers import StringTransport
+from twisted.test.test_internet import DummyProducer
+from twisted.trial import unittest
+from twisted.web import http
+from twisted.web.test.test_http import DummyHTTPHandler
+
+skipH2 = None
+
+try:
+    from twisted.web.http2 import H2Connection
+
+    # These third-party imports are guaranteed to be present if HTTP/2 support
+    # is compiled in. We do not use them in the main code: only in the tests.
+    import h2
+    import hyperframe
+    from hpack.hpack import Encoder, Decoder
+except ImportError:
+    skipH2 = "HTTP/2 support not enabled"
+
+
+
+# Define some helpers for the rest of these tests.
+class FrameFactory(object):
+    """
+    A class containing lots of helper methods and state to build frames. This
+    allows test cases to easily build correct HTTP/2 frames to feed to
+    hyper-h2.
+    """
+    def __init__(self):
+        self.encoder = Encoder()
+
+
+    def refreshEncoder(self):
+        self.encoder = Encoder()
+
+
+    def preamble(self):
+        return b'PRI * HTTP/2.0\r\n\r\nSM\r\n\r\n'
+
+
+    def buildHeadersFrame(self,
+                          headers,
+                          flags=[],
+                          streamID=1,
+                          **priorityKwargs):
+        """
+        Builds a single valid headers frame out of the contained headers.
+        """
+        f = hyperframe.frame.HeadersFrame(streamID)
+        f.data = self.encoder.encode(headers)
+        f.flags.add('END_HEADERS')
+        for flag in flags:
+            f.flags.add(flag)
+
+        for k, v in priorityKwargs.items():
+            setattr(f, k, v)
+
+        return f
+
+
+    def buildDataFrame(self, data, flags=None, streamID=1):
+        """
+        Builds a single data frame out of a chunk of data.
+        """
+        flags = set(flags) if flags is not None else set()
+        f = hyperframe.frame.DataFrame(streamID)
+        f.data = data
+        f.flags = flags
+        return f
+
+
+    def buildSettingsFrame(self, settings, ack=False):
+        """
+        Builds a single settings frame.
+        """
+        f = hyperframe.frame.SettingsFrame(0)
+        if ack:
+            f.flags.add('ACK')
+
+        f.settings = settings
+        return f
+
+
+    def buildWindowUpdateFrame(self, streamID, increment):
+        """
+        Builds a single WindowUpdate frame.
+        """
+        f = hyperframe.frame.WindowUpdateFrame(streamID)
+        f.window_increment = increment
+        return f
+
+
+    def buildGoAwayFrame(self, lastStreamID, errorCode=0, additionalData=b''):
+        """
+        Builds a single GOAWAY frame.
+        """
+        f = hyperframe.frame.GoAwayFrame(0)
+        f.error_code = errorCode
+        f.last_stream_id = lastStreamID
+        f.additional_data = additionalData
+        return f
+
+
+    def buildRstStreamFrame(self, streamID, errorCode=0):
+        """
+        Builds a single RST_STREAM frame.
+        """
+        f = hyperframe.frame.RstStreamFrame(streamID)
+        f.error_code = errorCode
+        return f
+
+
+    def buildPriorityFrame(self,
+                           streamID,
+                           weight,
+                           dependsOn=0,
+                           exclusive=False):
+        """
+        Builds a single priority frame.
+        """
+        f = hyperframe.frame.PriorityFrame(streamID)
+        f.depends_on = dependsOn
+        f.stream_weight = weight
+        f.exclusive = exclusive
+        return f
+
+
+    def buildPushPromiseFrame(self,
+                              streamID,
+                              promisedStreamID,
+                              headers,
+                              flags=[]):
+        """
+        Builds a single Push Promise frame.
+        """
+        f = hyperframe.frame.PushPromiseFrame(streamID)
+        f.promised_stream_id = promisedStreamID
+        f.data = self.encoder.encode(headers)
+        f.flags = set(flags)
+        f.flags.add('END_HEADERS')
+        return f
+
+
+
+class FrameBuffer(object):
+    """
+    A test object that converts data received from Twisted's HTTP/2 stack and
+    turns it into a sequence of hyperframe frame objects.
+
+    This is primarily used to make it easier to write and debug tests: rather
+    than have to serialize the expected frames and then do byte-level
+    comparison (which can be unclear in debugging output), this object makes it
+    possible to work with the frames directly.
+
+    It also ensures that headers are properly decompressed.
+    """
+    def __init__(self):
+        self.decoder = Decoder()
+        self._data = b''
+
+
+    def receiveData(self, data):
+        self._data += data
+
+
+    def __iter__(self):
+        return self
+
+
+    def next(self):
+        if len(self._data) < 9:
+            raise StopIteration()
+
+        frame, length = hyperframe.frame.Frame.parse_frame_header(
+            self._data[:9]
+        )
+        if len(self._data) < length + 9:
+            raise StopIteration()
+
+        frame.parse_body(memoryview(self._data[9:9+length]))
+        self._data = self._data[9+length:]
+
+        if isinstance(frame, hyperframe.frame.HeadersFrame):
+            frame.data = self.decoder.decode(frame.data)
+
+        return frame
+
+
+    __next__ = next
+
+
+
+def buildRequestFrames(headers, data, frameFactory=None, streamID=1):
+    """
+    Provides a sequence of HTTP/2 frames that encode a single HTTP request.
+    This should be used when you want to control the serialization yourself,
+    e.g. because you want to interleave other frames with these. If that's not
+    necessary, prefer L{buildRequestBytes}.
+
+    @param headers: The HTTP/2 headers to send.
+    @type headers: L{list} of L{tuple} of L{bytes}
+
+    @param data: The HTTP data to send. Each list entry will be sent in its own
+    frame.
+    @type data: L{list} of L{bytes}
+
+    @param frameFactory: The L{FrameFactory} that will be used to construct the
+    frames.
+    @type frameFactory: L{FrameFactory}
+
+    @param streamID: The ID of the stream on which to send the request.
+    @type streamID: L{int}
+    """
+    if frameFactory is None:
+        frameFactory = FrameFactory()
+
+    frames = []
+    frames.append(
+        frameFactory.buildHeadersFrame(headers=headers, streamID=streamID)
+    )
+    frames.extend(
+        frameFactory.buildDataFrame(chunk, streamID=streamID) for chunk in data
+    )
+    frames[-1].flags.add('END_STREAM')
+    return frames
+
+
+
+def buildRequestBytes(headers, data, frameFactory=None, streamID=1):
+    """
+    Provides the byte sequence for a collection of HTTP/2 frames representing
+    the provided request.
+
+    @param headers: The HTTP/2 headers to send.
+    @type headers: L{list} of L{tuple} of L{bytes}
+
+    @param data: The HTTP data to send. Each list entry will be sent in its own
+    frame.
+    @type data: L{list} of L{bytes}
+
+    @param frameFactory: The L{FrameFactory} that will be used to construct the
+    frames.
+    @type frameFactory: L{FrameFactory}
+
+    @param streamID: The ID of the stream on which to send the request.
+    @type streamID: L{int}
+    """
+    frames = buildRequestFrames(headers, data, frameFactory, streamID)
+    return b''.join(f.serialize() for f in frames)
+
+
+
+class ChunkedHTTPHandler(http.Request):
+    """
+    A HTTP request object that writes chunks of data back to the network based
+    on the URL.
+
+    Must be called with a path /chunked/<num_chunks>
+    """
+    chunkData = b'hello world!'
+
+    def process(self):
+        chunks = int(self.uri.split(b'/')[-1])
+        self.setResponseCode(200)
+
+        for _ in range(chunks):
+            self.write(self.chunkData)
+
+        self.finish()
+
+
+
+class ConsumerDummyHandler(http.Request):
+    """
+    This is a HTTP request handler that works with the C{IPushProducer}
+    implementation in the L{H2Stream} object. No current IRequest object does
+    that, but in principle future implementations could: that codepath should
+    therefore be tested.
+
+    The response is some important details of the request in JSON form.
+    """
+    def __init__(self, *args, **kwargs):
+        http.Request.__init__(self, *args, **kwargs)
+
+        # Production starts paused.
+        self._channel.pauseProducing()
+        self._requestReceived = False
+        self._data = None
+
+
+    def acceptData(self):
+        """
+        Start the data pipe.
+        """
+        self._channel.resumeProducing()
+
+
+    def requestReceived(self, *args, **kwargs):
+        self._requestReceived = True
+        return http.Request.requestReceived(self, *args, **kwargs)
+
+
+    def process(self):
+        self.setResponseCode(200)
+        self._data = self.content.read()
+        returnData = {
+            "headers": list(self.requestHeaders.getAllRawHeaders()),
+            "body": self._data,
+        }
+        self.write(json.dumps(returnData).encode('utf-8'))
+        self.finish()
+
+
+
+class AbortingConsumerDummyHandler(ConsumerDummyHandler):
+    """
+    This is a HTTP request handler that works with the C{IPushProducer}
+    implementation in the L{H2Stream} object. The difference between this and
+    the ConsumerDummyHandler is that after resuming production it immediately
+    aborts it again.
+    """
+    def acceptData(self):
+        """
+        Start and then immediately stop the data pipe.
+        """
+        self._channel.resumeProducing()
+        self._channel.stopProducing()
+
+
+
+class DummyProducerHandler(http.Request):
+    """
+    An HTTP request handler that registers a dummy producer to serve the body.
+
+    The owner must call C{finish} to complete the response.
+    """
+    def process(self):
+        self.setResponseCode(200)
+        self.registerProducer(DummyProducer(), True)
+
+
+
+class DummyPullProducerHandler(http.Request):
+    """
+    An HTTP request handler that registers a dummy pull producer to serve the
+    body.
+
+    The owner must call C{finish} to complete the response.
+    """
+    def process(self):
+        self._actualProducer = NonStreamingProducer(self)
+        self.setResponseCode(200)
+        self.registerProducer(self._actualProducer, False)
+
+
+
+class HTTP2ServerTests(unittest.TestCase):
+    if skipH2:
+        skip = skipH2
+
+
+    getRequestHeaders = [
+        (b':method', b'GET'),
+        (b':authority', b'localhost'),
+        (b':path', b'/'),
+        (b':scheme', b'https'),
+        (b'user-agent', b'twisted-test-code'),
+        (b'custom-header', b'1'),
+        (b'custom-header', b'2'),
+    ]
+
+
+    postRequestHeaders = [
+        (b':method', b'POST'),
+        (b':authority', b'localhost'),
+        (b':path', b'/post_endpoint'),
+        (b':scheme', b'https'),
+        (b'user-agent', b'twisted-test-code'),
+        (b'content-length', b'25'),
+    ]
+
+
+    postRequestData = [b"hello ", b"world, ", b"it's ", b"http/2!"]
+
+
+    getResponseHeaders = [
+        (b':status', b'200'),
+        (b'request', b'/'),
+        (b'command', b'GET'),
+        (b'version', b'HTTP/2'),
+        (b'content-length', b'13'),
+    ]
+
+
+    getResponseData = b"'''\nNone\n'''\n"
+
+
+    postResponseHeaders = [
+        (b':status', b'200'),
+        (b'request', b'/post_endpoint'),
+        (b'command', b'POST'),
+        (b'version', b'HTTP/2'),
+        (b'content-length', b'36'),
+    ]
+
+
+    postResponseData = b"'''\n25\nhello world, it's http/2!'''\n"
+
+
+    def test_basicRequest(self):
+        """
+        Send request over a TCP connection and confirm that we get back the
+        expected data in the order and style we expect.
+        """
+        # This test is complex because it validates the data very closely: it
+        # specifically checks frame ordering and type.
+        f = FrameFactory()
+        b = StringTransport()
+        a = H2Connection()
+        a.requestFactory = DummyHTTPHandler
+
+        requestBytes = f.preamble()
+        requestBytes += buildRequestBytes(self.getRequestHeaders, [], f)
+        a.makeConnection(b)
+        # one byte at a time, to stress the implementation.
+        for byte in iterbytes(requestBytes):
+            a.dataReceived(byte)
+
+        def validate(streamID):
+            buffer = FrameBuffer()
+            buffer.receiveData(b.value())
+            frames = list(buffer)
+
+            self.assertEqual(len(frames), 4)
+            self.assertTrue(all(f.stream_id == 1 for f in frames[1:]))
+
+            self.assertTrue(
+                isinstance(frames[1], hyperframe.frame.HeadersFrame)
+            )
+            self.assertTrue(isinstance(frames[2], hyperframe.frame.DataFrame))
+            self.assertTrue(isinstance(frames[3], hyperframe.frame.DataFrame))
+
+            self.assertEqual(
+                dict(frames[1].data), dict(self.getResponseHeaders)
+            )
+            self.assertEqual(frames[2].data, self.getResponseData)
+            self.assertEqual(frames[3].data, b'')
+            self.assertTrue('END_STREAM' in frames[3].flags)
+
+        return a._streamCleanupCallbacks[1].addCallback(validate)
+
+
+    def test_postRequest(self):
+        """
+        Send a POST request and confirm that the data is safely transferred.
+        """
+        f = FrameFactory()
+        b = StringTransport()
+        a = H2Connection()
+        a.requestFactory = DummyHTTPHandler
+
+        requestBytes = f.preamble()
+        requestBytes += buildRequestBytes(
+            self.postRequestHeaders, self.postRequestData, f
+        )
+        a.makeConnection(b)
+        # one byte at a time, to stress the implementation.
+        for byte in iterbytes(requestBytes):
+            a.dataReceived(byte)
+
+        def validate(streamID):
+            buffer = FrameBuffer()
+            buffer.receiveData(b.value())
+            frames = list(buffer)
+
+            # One Settings frame, 8 WindowUpdate frames, one Headers frame,
+            # and two Data frames
+            self.assertEqual(len(frames), 12)
+            self.assertTrue(all(f.stream_id == 1 for f in frames[-3:]))
+
+            self.assertTrue(
+                isinstance(frames[-3], hyperframe.frame.HeadersFrame)
+            )
+            self.assertTrue(isinstance(frames[-2], hyperframe.frame.DataFrame))
+            self.assertTrue(isinstance(frames[-1], hyperframe.frame.DataFrame))
+
+            self.assertEqual(
+                dict(frames[-3].data), dict(self.postResponseHeaders)
+            )
+            self.assertEqual(frames[-2].data, self.postResponseData)
+            self.assertEqual(frames[-1].data, b'')
+            self.assertTrue('END_STREAM' in frames[-1].flags)
+
+        return a._streamCleanupCallbacks[1].addCallback(validate)
+
+
+    def test_interleavedRequests(self):
+        """
+        Many interleaved POST requests all get received and responded to
+        appropriately.
+        """
+        # Unfortunately this test is pretty complex.
+        REQUEST_COUNT = 40
+
+        f = FrameFactory()
+        b = StringTransport()
+        a = H2Connection()
+        a.requestFactory = DummyHTTPHandler
+
+        # Stream IDs are always odd numbers.
+        streamIDs = list(range(1, REQUEST_COUNT * 2, 2))
+        frames = [
+            buildRequestFrames(
+                self.postRequestHeaders, self.postRequestData, f, streamID
+            ) for streamID in streamIDs
+        ]
+
+        requestBytes = f.preamble()
+
+        # Interleave the frames. That is, send one frame from each stream at a
+        # time. This wacky line lets us do that.
+        frames = itertools.chain.from_iterable(zip(*frames))
+        requestBytes += b''.join(frame.serialize() for frame in frames)
+        a.makeConnection(b)
+        # one byte at a time, to stress the implementation.
+        for byte in iterbytes(requestBytes):
+            a.dataReceived(byte)
+
+        def validate(results):
+            buffer = FrameBuffer()
+            buffer.receiveData(b.value())
+            frames = list(buffer)
+
+            # We expect 1 Settings frame for the connection, and then 11 frames
+            # *per stream* (8 WindowUpdate frames, 1 Headers frame,
+            # 2 Data frames).
+            self.assertEqual(len(frames), 1 + (11 * 40))
+
+            # Let's check the data is ok. We need the non-WindowUpdate frames
+            # for each stream.
+            for streamID in streamIDs:
+                streamFrames = [
+                    f for f in frames if f.stream_id == streamID and
+                    not isinstance(f, hyperframe.frame.WindowUpdateFrame)
+                ]
+
+                self.assertEqual(len(streamFrames), 3)
+
+                self.assertEqual(
+                    dict(streamFrames[0].data), dict(self.postResponseHeaders)
+                )
+                self.assertEqual(streamFrames[1].data, self.postResponseData)
+                self.assertEqual(streamFrames[2].data, b'')
+                self.assertTrue('END_STREAM' in streamFrames[2].flags)
+
+        return defer.DeferredList(
+            list(a._streamCleanupCallbacks.values())
+        ).addCallback(validate)
+
+
+    def test_sendAccordingToPriority(self):
+        """
+        Data in responses is interleaved according to HTTP/2 priorities.
+        """
+        # We want to start three parallel GET requests that will each return
+        # four chunks of data. These chunks will be interleaved according to
+        # HTTP/2 priorities. Stream 1 will be set to weight 64, Stream 3 to
+        # weight 32, and Stream 5 to weight 16 but dependent on Stream 1.
+        # That will cause data frames for these streams to be emitted in this
+        # order: 1, 1, 3, 1, 1, 3, 1, 5, 3, 3, 5, 3, 5, 5, 5.
+        #
+        # The reason there are so many frames is because the implementation
+        # interleaves stream completion according to priority order as well,
+        # because it is sent on a Data frame.
+        #
+        # This doesn't fully test priority, but tests *almost* enough of it to
+        # be worthwhile.
+        f = FrameFactory()
+        b = StringTransport()
+        a = H2Connection()
+        a.requestFactory = ChunkedHTTPHandler
+        getRequestHeaders = self.getRequestHeaders
+        getRequestHeaders[2] = (b':path', b'/chunked/4')
+
+        frames = [
+            buildRequestFrames(getRequestHeaders, [], f, streamID)
+            for streamID in [1, 3, 5]
+        ]
+
+        # Set the priorities. The first two will use their HEADERS frame, the
+        # third will have a PRIORITY frame sent before the headers.
+        frames[0][0].flags.add('PRIORITY')
+        frames[0][0].stream_weight = 64
+
+        frames[1][0].flags.add('PRIORITY')
+        frames[1][0].stream_weight = 32
+
+        priorityFrame = f.buildPriorityFrame(
+            streamID=5,
+            weight=16,
+            dependsOn=1,
+            exclusive=True,
+        )
+        frames[2].insert(0, priorityFrame)
+
+        frames = itertools.chain.from_iterable(frames)
+        requestBytes = f.preamble()
+        requestBytes += b''.join(frame.serialize() for frame in frames)
+
+        a.makeConnection(b)
+        # one byte at a time, to stress the implementation.
+        for byte in iterbytes(requestBytes):
+            a.dataReceived(byte)
+
+        def validate(results):
+            buffer = FrameBuffer()
+            buffer.receiveData(b.value())
+            frames = list(buffer)
+
+            # We expect 1 Settings frame for the connection, and then 6 frames
+            # per stream (1 Headers frame, 5 data frames), for a total of 19.
+            self.assertEqual(len(frames), 19)
+
+            streamIDs = [
+                f.stream_id for f in frames
+                if isinstance(f, hyperframe.frame.DataFrame)
+            ]
+            expectedOrder = [1, 1, 3, 1, 1, 3, 1, 5, 3, 3, 5, 3, 5, 5, 5]
+            self.assertEqual(streamIDs, expectedOrder)
+
+        return defer.DeferredList(
+            list(a._streamCleanupCallbacks.values())
+        ).addCallback(validate)
+
+
+    def test_protocolErrorTerminatesConnection(self):
+        """
+        A protocol error from the remote peer terminates the connection.
+        """
+        f = FrameFactory()
+        b = StringTransport()
+        a = H2Connection()
+        a.requestFactory = DummyHTTPHandler
+
+        # We're going to open a stream and then send a PUSH_PROMISE frame,
+        # which is forbidden.
+        requestBytes = f.preamble()
+        requestBytes += buildRequestBytes(self.getRequestHeaders, [], f)
+        requestBytes += f.buildPushPromiseFrame(
+            streamID=1,
+            promisedStreamID=2,
+            headers=self.getRequestHeaders,
+            flags=['END_HEADERS'],
+        ).serialize()
+
+        a.makeConnection(b)
+        # one byte at a time, to stress the implementation.
+        for byte in iterbytes(requestBytes):
+            a.dataReceived(byte)
+
+            # Check whether the transport got shut down: if it did, stop
+            # sending more data.
+            if b.disconnecting:
+                break
+
+        buffer = FrameBuffer()
+        buffer.receiveData(b.value())
+        frames = list(buffer)
+
+        # The send loop never gets to terminate the stream, but *some* data
+        # does get sent. We get a Settings frame, a Headers frame, a Data
+        # frame, and then the GoAway frame.
+        self.assertEqual(len(frames), 4)
+        self.assertTrue(
+            isinstance(frames[3], hyperframe.frame.GoAwayFrame)
+        )
+        self.assertTrue(b.disconnecting)
+        self.assertFalse(a._sender.running)
+
+
+    def test_streamProducingData(self):
+        """
+        The H2Stream data implements IPushProducer, and can have its data
+        production controlled by the Request if the Request chooses to.
+        """
+        f = FrameFactory()
+        b = StringTransport()
+        a = H2Connection()
+        a.requestFactory = ConsumerDummyHandler
+
+        # We're going to send in a POST request.
+        requestBytes = f.preamble()
+        requestBytes += buildRequestBytes(
+            self.postRequestHeaders, self.postRequestData, f
+        )
+        a.makeConnection(b)
+        # one byte at a time, to stress the implementation.
+        for byte in iterbytes(requestBytes):
+            a.dataReceived(byte)
+
+        # At this point no data should have been received by the request *or*
+        # the response. We need to dig the request out of the tree of objects.
+        request = a.streams[1]._request
+        self.assertFalse(request._requestReceived)
+
+        # We should have only received the Settings frame. It's important that
+        # the WindowUpdate frames don't land before data is delivered to the
+        # Request.
+        buffer = FrameBuffer()
+        buffer.receiveData(b.value())
+        frames = list(buffer)
+        self.assertEqual(len(frames), 1)
+
+        # At this point, we can kick off the producing. This will force the
+        # H2Stream object to deliver the request data all at once, so check
+        # that it was delivered correctly.
+        request.acceptData()
+        self.assertTrue(request._requestReceived)
+        self.assertTrue(request._data, b"hello world, it's http/2!")
+
+        # *That* will have also caused the H2Connection object to emit almost
+        # all the data it needs. That'll be a Headers frame and the first Data
+        # frame, as well as two WindowUpdate frames.
+        buffer = FrameBuffer()
+        buffer.receiveData(b.value())
+        frames = list(buffer)
+        self.assertEqual(len(frames), 5)
+
+        def validate(streamID):
+            # Confirm that the response is ok.
+            buffer = FrameBuffer()
+            buffer.receiveData(b.value())
+            frames = list(buffer)
+
+            # The only new frame here is one more Data frame that carries the
+            # END_STREAM sentinel.
+            self.assertEqual(len(frames), 6)
+            self.assertTrue('END_STREAM' in frames[-1].flags)
+
+        return a._streamCleanupCallbacks[1].addCallback(validate)
+
+
+    def test_abortStreamProducingData(self):
+        """
+        The H2Stream data implements IPushProducer, and can have its data
+        production controlled by the Request if the Request chooses to.
+        When the production is stopped, that causes the stream connection to
+        be lost.
+        """
+        f = FrameFactory()
+        b = StringTransport()
+        a = H2Connection()
+        a.requestFactory = AbortingConsumerDummyHandler
+
+        # We're going to send in a POST request.
+        frames = buildRequestFrames(
+            self.postRequestHeaders, self.postRequestData, f
+        )
+        frames[-1].flags = set()  # Remove END_STREAM flag.
+        requestBytes = f.preamble()
+        requestBytes += b''.join(f.serialize() for f in frames)
+        a.makeConnection(b)
+        # one byte at a time, to stress the implementation.
+        for byte in iterbytes(requestBytes):
+            a.dataReceived(byte)
+
+        # At this point no data should have been received by the request *or*
+        # the response. We need to dig the request out of the tree of objects.
+        request = a.streams[1]._request
+        self.assertFalse(request._requestReceived)
+
+        # Save off the cleanup deferred now, it'll be removed when the
+        # RstStream frame is sent.
+        cleanupCallback = a._streamCleanupCallbacks[1]
+
+        # At this point, we can kick off the production and immediate abort.
+        request.acceptData()
+
+        # The stream will now have been aborted.
+        def validate(streamID):
+            # Confirm that the response is ok.
+            buffer = FrameBuffer()
+            buffer.receiveData(b.value())
+            frames = list(buffer)
+
+            # We expect a Settings frame, two WindowUpdate frames, and a
+            # RstStream frame.
+            self.assertEqual(len(frames), 4)
+            self.assertTrue(
+                isinstance(frames[3], hyperframe.frame.RstStreamFrame)
+            )
+            self.assertEqual(frames[3].stream_id, 1)
+
+        return cleanupCallback.addCallback(validate)
+
+
+    def test_terminatedRequest(self):
+        """
+        When a RstStream frame is received, the L{H2Connection} and L{H2Stream}
+        objects tear down the L{http.Request} and swallow all outstanding
+        writes.
+        """
+        # Here we want to use the DummyProducerHandler primarily for the side
+        # effect it has of not writing to the connection. That means we can
+        # delay some writes until *after* the RstStream frame is received.
+        f = FrameFactory()
+        b = StringTransport()
+        a = H2Connection()
+        a.requestFactory = DummyProducerHandler
+
+        requestBytes = f.preamble()
+        requestBytes += buildRequestBytes(self.getRequestHeaders, [], f)
+        a.makeConnection(b)
+        # one byte at a time, to stress the implementation.
+        for byte in iterbytes(requestBytes):
+            a.dataReceived(byte)
+
+        # Get the request object.
+        request = a.streams[1]._request
+
+        # Send two writes in.
+        request.write(b"first chunk")
+        request.write(b"second chunk")
+
+        # Save off the cleanup deferred now, it'll be removed when the
+        # RstStream frame is received.
+        cleanupCallback = a._streamCleanupCallbacks[1]
+
+        # Now fire the RstStream frame.
+        a.dataReceived(
+            f.buildRstStreamFrame(1, errorCode=1).serialize()
+        )
+
+        # This should have cancelled the request.
+        self.assertTrue(request._disconnected)
+        self.assertTrue(request._channel is None)
+
+        # An attempt to write should at this point raise an exception.
+        self.assertRaises(KeyError, request.write, b"third chunk")
+
+        # Check that everything is fine.
+        # We expect that only the Settings, Headers, and one Data frame will
+        # have been emitted. The first Data frame will be the original write,
+        # which got executed *before* the RstStream frame was received. The
+        # second write is lost because the looping call never had another
+        # chance to execute before the RstStream frame got processed.
+        def validate(streamID):
+            buffer = FrameBuffer()
+            buffer.receiveData(b.value())
+            frames = list(buffer)
+
+            self.assertEqual(len(frames), 3)
+            self.assertTrue(all(f.stream_id == 1 for f in frames[1:]))
+
+            self.assertTrue(
+                isinstance(frames[1], hyperframe.frame.HeadersFrame)
+            )
+
+            # Grab the data from the frames.
+            dataChunks = [
+                f.data for f in frames
+                if isinstance(f, hyperframe.frame.DataFrame)
+            ]
+            self.assertEqual(dataChunks, [b"first chunk"])
+
+        return cleanupCallback.addCallback(validate)
+
+
+    def test_terminatedConnection(self):
+        """
+        When a GoAway frame is received, the L{H2Connection} and L{H2Stream}
+        objects tear down all outstanding L{http.Request} objects and stop all
+        writing.
+        """
+        # Here we want to use the DummyProducerHandler primarily for the side
+        # effect it has of not writing to the connection. That means we can
+        # delay some writes until *after* the GoAway frame is received.
+        f = FrameFactory()
+        b = StringTransport()
+        a = H2Connection()
+        a.requestFactory = DummyProducerHandler
+
+        requestBytes = f.preamble()
+        requestBytes += buildRequestBytes(self.getRequestHeaders, [], f)
+        a.makeConnection(b)
+        # one byte at a time, to stress the implementation.
+        for byte in iterbytes(requestBytes):
+            a.dataReceived(byte)
+
+        # Get the request object.
+        request = a.streams[1]._request
+
+        # Send two writes in.
+        request.write(b"first chunk")
+        request.write(b"second chunk")
+
+        # Save off the cleanup deferred now, it'll be removed when the
+        # GoAway frame is received.
+        cleanupCallback = a._streamCleanupCallbacks[1]
+
+        # Now fire the GoAway frame.
+        a.dataReceived(
+            f.buildGoAwayFrame(lastStreamID=0).serialize()
+        )
+
+        # This should have cancelled the request.
+        self.assertTrue(request._disconnected)
+        self.assertTrue(request._channel is None)
+
+        # It should also have cancelled the sending loop.
+        self.assertFalse(a._sender.running)
+
+        # Check that everything is fine.
+        # We expect that only the Settings, Headers, and one Data frame will
+        # have been emitted. The first Data frame will be the original write,
+        # which got executed *before* the GoAway frame was received. The
+        # second write is lost because the looping call never had another
+        # chance to execute before the GoAway frame got processed.
+        def validate(streamID):
+            buffer = FrameBuffer()
+            buffer.receiveData(b.value())
+            frames = list(buffer)
+
+            self.assertEqual(len(frames), 3)
+            self.assertTrue(all(f.stream_id == 1 for f in frames[1:]))
+
+            self.assertTrue(
+                isinstance(frames[1], hyperframe.frame.HeadersFrame)
+            )
+
+            # Grab the data from the frames.
+            dataChunks = [
+                f.data for f in frames
+                if isinstance(f, hyperframe.frame.DataFrame)
+            ]
+            self.assertEqual(dataChunks, [b"first chunk"])
+
+        return cleanupCallback.addCallback(validate)
+
+
+    def test_respondWith100Continue(self):
+        """
+        Requests containing Expect: 100-continue cause provisional 100
+        responses to be emitted.
+        """
+        f = FrameFactory()
+        b = StringTransport()
+        a = H2Connection()
+        a.requestFactory = DummyHTTPHandler
+
+        # Add Expect: 100-continue for this request.
+        headers = self.getRequestHeaders + [(b'expect', b'100-continue')]
+
+        requestBytes = f.preamble()
+        requestBytes += buildRequestBytes(headers, [], f)
+        a.makeConnection(b)
+        # one byte at a time, to stress the implementation.
+        for byte in iterbytes(requestBytes):
+            a.dataReceived(byte)
+
+        # We expect 5 frames now: Settings, two Headers frames, and two Data
+        # frames. We're only really interested in validating the first Headers
+        # frame which contains the 100.
+        def validate(streamID):
+            buffer = FrameBuffer()
+            buffer.receiveData(b.value())
+            frames = list(buffer)
+
+            self.assertEqual(len(frames), 5)
+            self.assertTrue(all(f.stream_id == 1 for f in frames[1:]))
+
+            self.assertTrue(
+                isinstance(frames[1], hyperframe.frame.HeadersFrame)
+            )
+            self.assertEqual(
+                frames[1].data, [(b':status', b'100')]
+            )
+            self.assertTrue('END_STREAM' in frames[-1].flags)
+
+        return a._streamCleanupCallbacks[1].addCallback(validate)
+
+
+    def test_respondWith400(self):
+        """
+        Triggering the call to _respondToBadRequestAndDisconnect leads to a
+        400 error being sent automatically and the stream being torn down.
+        """
+        # The only "natural" way to trigger this in the current codebase is to
+        # send a multipart/form-data request that the cgi module doesn't like.
+        # That's absurdly hard, so instead we'll just call it ourselves. For
+        # this reason we use the DummyProducerHandler, which doesn't write the
+        # headers straight away.
+        f = FrameFactory()
+        b = StringTransport()
+        a = H2Connection()
+        a.requestFactory = DummyProducerHandler
+
+        requestBytes = f.preamble()
+        requestBytes += buildRequestBytes(self.getRequestHeaders, [], f)
+        a.makeConnection(b)
+        # one byte at a time, to stress the implementation.
+        for byte in iterbytes(requestBytes):
+            a.dataReceived(byte)
+
+        # Grab the request and the completion callback.
+        stream = a.streams[1]
+        request = stream._request
+        cleanupCallback = a._streamCleanupCallbacks[1]
+
+        # Abort the stream.
+        stream._respondToBadRequestAndDisconnect()
+
+        # This should have cancelled the request.
+        self.assertTrue(request._disconnected)
+        self.assertTrue(request._channel is None)
+
+        # We expect 2 frames Settings and the 400 Headers.
+        def validate(streamID):
+            buffer = FrameBuffer()
+            buffer.receiveData(b.value())
+            frames = list(buffer)
+
+            self.assertEqual(len(frames), 2)
+
+            self.assertTrue(
+                isinstance(frames[1], hyperframe.frame.HeadersFrame)
+            )
+            self.assertEqual(
+                frames[1].data, [(b':status', b'400')]
+            )
+            self.assertTrue('END_STREAM' in frames[-1].flags)
+
+        return cleanupCallback.addCallback(validate)
+
+
+    def test_loseH2StreamConnection(self):
+        """
+        Calling L{Request.loseConnection} causes all data that has previously
+        been sent to be flushed, and then the stream cleanly closed.
+        """
+        # Here we again want to use the DummyProducerHandler because it doesn't
+        # close the connection on its own.
+        f = FrameFactory()
+        b = StringTransport()
+        a = H2Connection()
+        a.requestFactory = DummyProducerHandler
+
+        requestBytes = f.preamble()
+        requestBytes += buildRequestBytes(self.getRequestHeaders, [], f)
+        a.makeConnection(b)
+        # one byte at a time, to stress the implementation.
+        for byte in iterbytes(requestBytes):
+            a.dataReceived(byte)
+
+        # Grab the request.
+        stream = a.streams[1]
+        request = stream._request
+
+        # Send in some writes.
+        dataChunks = [b'hello', b'world', b'here', b'are', b'some', b'writes']
+        for chunk in dataChunks:
+            request.write(chunk)
+
+        # Now lose the connection.
+        request.loseConnection()
+
+        # Check that the data was all written out correctly and that the stream
+        # state is cleaned up.
+        def validate(streamID):
+            buffer = FrameBuffer()
+            buffer.receiveData(b.value())
+            frames = list(buffer)
+
+            # Settings, Headers, 7 Data frames.
+            self.assertEqual(len(frames), 9)
+            self.assertTrue(all(f.stream_id == 1 for f in frames[1:]))
+
+            self.assertTrue(
+                isinstance(frames[1], hyperframe.frame.HeadersFrame)
+            )
+            self.assertTrue('END_STREAM' in frames[-1].flags)
+
+            receivedDataChunks = [
+                f.data for f in frames
+                if isinstance(f, hyperframe.frame.DataFrame)
+            ]
+            self.assertEqual(
+                receivedDataChunks,
+                dataChunks + [b""],
+            )
+
+        return a._streamCleanupCallbacks[1].addCallback(validate)
+
+
+    def test_cannotRegisterTwoProducers(self):
+        """
+        The L{H2Stream} object forbids registering two producers.
+        """
+        f = FrameFactory()
+        b = StringTransport()
+        a = H2Connection()
+        a.requestFactory = DummyProducerHandler
+
+        requestBytes = f.preamble()
+        requestBytes += buildRequestBytes(self.getRequestHeaders, [], f)
+        a.makeConnection(b)
+        # one byte at a time, to stress the implementation.
+        for byte in iterbytes(requestBytes):
+            a.dataReceived(byte)
+
+        # Grab the request.
+        stream = a.streams[1]
+        request = stream._request
+
+        self.assertRaises(ValueError, stream.registerProducer, request, True)
+
+
+    def test_handlesPullProducer(self):
+        """
+        L{Request} objects that have registered pull producers get blocked and
+        unblocked according to HTTP/2 flow control.
+        """
+        f = FrameFactory()
+        b = StringTransport()
+        a = H2Connection()
+        a.requestFactory = DummyPullProducerHandler
+
+        # Send the request.
+        requestBytes = f.preamble()
+        requestBytes += buildRequestBytes(
+            self.getRequestHeaders, [], f
+        )
+        a.makeConnection(b)
+        # one byte at a time, to stress the implementation.
+        for byte in iterbytes(requestBytes):
+            a.dataReceived(byte)
+
+        # Get the producer completion deferred and ensure we call
+        # request.finish.
+        stream = a.streams[1]
+        request = stream._request
+        producerComplete = request._actualProducer.result
+        producerComplete.addCallback(lambda x: request.finish())
+
+        # Check that the sending loop sends all the appropriate data.
+        def validate(streamID):
+            buffer = FrameBuffer()
+            buffer.receiveData(b.value())
+            frames = list(buffer)
+
+            # Check that the stream is correctly terminated.
+            self.assertTrue('END_STREAM' in frames[-1].flags)
+
+            # Grab the data from the frames.
+            dataChunks = [
+                f.data for f in frames
+                if isinstance(f, hyperframe.frame.DataFrame)
+            ]
+            self.assertEqual(
+                dataChunks,
+                [
+                    b"0", b"1", b"2", b"3", b"4", b"5",
+                    b"6", b"7", b"8", b"9", b""
+                ]
+            )
+
+        return a._streamCleanupCallbacks[1].addCallback(validate)
+
+
+
+class H2FlowControlTests(unittest.TestCase):
+    """
+    Tests that ensure that we handle HTTP/2 flow control limits appropriately.
+    """
+    if skipH2:
+        skip = skipH2
+
+
+    getRequestHeaders = [
+        (b':method', b'GET'),
+        (b':authority', b'localhost'),
+        (b':path', b'/'),
+        (b':scheme', b'https'),
+        (b'user-agent', b'twisted-test-code'),
+    ]
+
+
+    getResponseData = b"'''\nNone\n'''\n"
+
+
+    postRequestHeaders = [
+        (b':method', b'POST'),
+        (b':authority', b'localhost'),
+        (b':path', b'/post_endpoint'),
+        (b':scheme', b'https'),
+        (b'user-agent', b'twisted-test-code'),
+        (b'content-length', b'25'),
+    ]
+
+
+    postRequestData = [b"hello ", b"world, ", b"it's ", b"http/2!"]
+
+
+    postResponseData = b"'''\n25\nhello world, it's http/2!'''\n"
+
+
+    def test_bufferExcessData(self):
+        """
+        When a L{Request} object is not using C{IProducer} to generate data and
+        so is not having backpressure exerted on it, the L{H2Stream} object
+        will buffer data until the flow control window is opened.
+        """
+        f = FrameFactory()
+        b = StringTransport()
+        a = H2Connection()
+        a.requestFactory = DummyHTTPHandler
+
+        # Shrink the window to 5 bytes, then send the request.
+        requestBytes = f.preamble()
+        requestBytes += f.buildSettingsFrame(
+            {h2.settings.INITIAL_WINDOW_SIZE: 5}
+        ).serialize()
+        requestBytes += buildRequestBytes(
+            self.getRequestHeaders, [], f
+        )
+        a.makeConnection(b)
+        # one byte at a time, to stress the implementation.
+        for byte in iterbytes(requestBytes):
+            a.dataReceived(byte)
+
+        # Send in WindowUpdate frames that open the window one byte at a time,
+        # to repeatedly temporarily unbuffer data. 5 bytes will have already
+        # been sent.
+        bonusFrames = len(self.getResponseData) - 5
+        for _ in range(bonusFrames):
+            frame = f.buildWindowUpdateFrame(streamID=1, increment=1)
+            a.dataReceived(frame.serialize())
+
+        # Give the sending loop a chance to catch up!
+        def validate(streamID):
+            buffer = FrameBuffer()
+            buffer.receiveData(b.value())
+            frames = list(buffer)
+
+            # Check that the stream is correctly terminated.
+            self.assertTrue('END_STREAM' in frames[-1].flags)
+
+            # Put the Data frames together to confirm we're all good.
+            actualResponseData = b''.join(
+                f.data for f in frames
+                if isinstance(f, hyperframe.frame.DataFrame)
+            )
+            self.assertEqual(self.getResponseData, actualResponseData)
+
+        return a._streamCleanupCallbacks[1].addCallback(validate)
+
+
+    def test_producerBlockingUnblocking(self):
+        """
+        L{Request} objects that have registered producers get blocked and
+        unblocked according to HTTP/2 flow control.
+        """
+        f = FrameFactory()
+        b = StringTransport()
+        a = H2Connection()
+        a.requestFactory = DummyProducerHandler
+
+        # Shrink the window to 5 bytes, then send the request.
+        requestBytes = f.preamble()
+        requestBytes += f.buildSettingsFrame(
+            {h2.settings.INITIAL_WINDOW_SIZE: 5}
+        ).serialize()
+        requestBytes += buildRequestBytes(
+            self.getRequestHeaders, [], f
+        )
+        a.makeConnection(b)
+        # one byte at a time, to stress the implementation.
+        for byte in iterbytes(requestBytes):
+            a.dataReceived(byte)
+
+        # Grab the request object.
+        stream = a.streams[1]
+        request = stream._request
+
+        # Confirm that the stream believes the producer is producing.
+        self.assertTrue(stream._producerProducing)
+
+        # Write 10 bytes to the connection.
+        request.write(b"helloworld")
+
+        # The producer should have been paused.
+        self.assertFalse(stream._producerProducing)
+        self.assertEqual(request.producer.events, ['pause'])
+
+        # Open the flow control window by 5 bytes. This should not unpause the
+        # producer.
+        a.dataReceived(
+            f.buildWindowUpdateFrame(streamID=1, increment=5).serialize()
+        )
+        self.assertFalse(stream._producerProducing)
+        self.assertEqual(request.producer.events, ['pause'])
+
+        # Open the connection window by 5 bytes as well. This should also not
+        # unpause the producer.
+        a.dataReceived(
+            f.buildWindowUpdateFrame(streamID=0, increment=5).serialize()
+        )
+        self.assertFalse(stream._producerProducing)
+        self.assertEqual(request.producer.events, ['pause'])
+
+        # Open it by five more bytes. This should unpause the producer.
+        a.dataReceived(
+            f.buildWindowUpdateFrame(streamID=1, increment=5).serialize()
+        )
+        self.assertTrue(stream._producerProducing)
+        self.assertEqual(request.producer.events, ['pause', 'resume'])
+
+        # Write another 10 bytes, which should force us to pause again. When
+        # written this chunk will be sent as one lot, simply because of the
+        # fact that the sending loop is not currently running.
+        request.write(b"helloworld")
+        self.assertFalse(stream._producerProducing)
+        self.assertEqual(request.producer.events, ['pause', 'resume', 'pause'])
+
+        # Open the window wide and then complete the request.
+        a.dataReceived(
+            f.buildWindowUpdateFrame(streamID=1, increment=50).serialize()
+        )
+        self.assertTrue(stream._producerProducing)
+        self.assertEqual(
+            request.producer.events,
+            ['pause', 'resume', 'pause', 'resume']
+        )
+        request.unregisterProducer()
+        request.finish()
+
+        # Check that the sending loop sends all the appropriate data.
+        def validate(streamID):
+            buffer = FrameBuffer()
+            buffer.receiveData(b.value())
+            frames = list(buffer)
+
+            # Check that the stream is correctly terminated.
+            self.assertTrue('END_STREAM' in frames[-1].flags)
+
+            # Grab the data from the frames.
+            dataChunks = [
+                f.data for f in frames
+                if isinstance(f, hyperframe.frame.DataFrame)
+            ]
+            self.assertEqual(
+                dataChunks,
+                [b"hello", b"world", b"helloworld", b""]
+            )
+
+        return a._streamCleanupCallbacks[1].addCallback(validate)
+
+
+    def test_flowControlExact(self):
+        """
+        Exactly filling the flow control window still blocks producers.
+        """
+        f = FrameFactory()
+        b = StringTransport()
+        a = H2Connection()
+        a.requestFactory = DummyProducerHandler
+
+        # Shrink the window to 5 bytes, then send the request.
+        requestBytes = f.preamble()
+        requestBytes += f.buildSettingsFrame(
+            {h2.settings.INITIAL_WINDOW_SIZE: 5}
+        ).serialize()
+        requestBytes += buildRequestBytes(
+            self.getRequestHeaders, [], f
+        )
+        a.makeConnection(b)
+        # one byte at a time, to stress the implementation.
+        for byte in iterbytes(requestBytes):
+            a.dataReceived(byte)
+
+        # Grab the request object.
+        stream = a.streams[1]
+        request = stream._request
+
+        # Confirm that the stream believes the producer is producing.
+        self.assertTrue(stream._producerProducing)
+
+        # Write 10 bytes to the connection. This should block the producer
+        # immediately.
+        request.write(b"helloworld")
+        self.assertFalse(stream._producerProducing)
+        self.assertEqual(request.producer.events, ['pause'])
+
+        # Despite the producer being blocked, write one more byte. This should
+        # not get sent or force any other data to be sent.
+        request.write(b"h")
+
+        # Open the window wide and then complete the request.
+        a.dataReceived(
+            f.buildWindowUpdateFrame(streamID=1, increment=50).serialize()
+        )
+        self.assertTrue(stream._producerProducing)
+        self.assertEqual(
+            request.producer.events,
+            ['pause', 'resume']
+        )
+        request.unregisterProducer()
+        request.finish()
+
+        # Check that the sending loop sends all the appropriate data.
+        def validate(streamID):
+            buffer = FrameBuffer()
+            buffer.receiveData(b.value())
+            frames = list(buffer)
+
+            # Check that the stream is correctly terminated.
+            self.assertTrue('END_STREAM' in frames[-1].flags)
+
+            # Grab the data from the frames.
+            dataChunks = [
+                f.data for f in frames
+                if isinstance(f, hyperframe.frame.DataFrame)
+            ]
+            self.assertEqual(dataChunks, [b"hello", b"world", b"h", b""])
+
+        return a._streamCleanupCallbacks[1].addCallback(validate)
+
+
+    def test_endingBlockedStream(self):
+        """
+        L{Request} objects that end a stream that is currently blocked behind
+        flow control can still end the stream and get cleaned up.
+        """
+        f = FrameFactory()
+        b = StringTransport()
+        a = H2Connection()
+        a.requestFactory = DummyProducerHandler
+
+        # Shrink the window to 5 bytes, then send the request.
+        requestBytes = f.preamble()
+        requestBytes += f.buildSettingsFrame(
+            {h2.settings.INITIAL_WINDOW_SIZE: 5}
+        ).serialize()
+        requestBytes += buildRequestBytes(
+            self.getRequestHeaders, [], f
+        )
+        a.makeConnection(b)
+        # one byte at a time, to stress the implementation.
+        for byte in iterbytes(requestBytes):
+            a.dataReceived(byte)
+
+        # Grab the request object.
+        stream = a.streams[1]
+        request = stream._request
+
+        # Confirm that the stream believes the producer is producing.
+        self.assertTrue(stream._producerProducing)
+
+        # Write 10 bytes to the connection, then complete the connection.
+        request.write(b"helloworld")
+        request.unregisterProducer()
+        request.finish()
+
+        # This should have completed the request.
+        self.assertTrue(request.finished)
+
+        # Open the window wide and then complete the request.
+        a.dataReceived(
+            f.buildWindowUpdateFrame(streamID=1, increment=50).serialize()
+        )
+
+        # Check that the sending loop sends all the appropriate data.
+        def validate(streamID):
+            buffer = FrameBuffer()
+            buffer.receiveData(b.value())
+            frames = list(buffer)
+
+            # Check that the stream is correctly terminated.
+            self.assertTrue('END_STREAM' in frames[-1].flags)
+
+            # Grab the data from the frames.
+            dataChunks = [
+                f.data for f in frames
+                if isinstance(f, hyperframe.frame.DataFrame)
+            ]
+            self.assertEqual(
+                dataChunks,
+                [b"hello", b"world", b""]
+            )
+
+        return a._streamCleanupCallbacks[1].addCallback(validate)
+
+
+    def test_responseWithoutBody(self):
+        """
+        We safely handle responses without bodies.
+        """
+        f = FrameFactory()
+        b = StringTransport()
+        a = H2Connection()
+
+        # We use the DummyProducerHandler just because we can guarantee that it
+        # doesn't end up with a body.
+        a.requestFactory = DummyProducerHandler
+
+        # Send the request.
+        requestBytes = f.preamble()
+        requestBytes += buildRequestBytes(
+            self.getRequestHeaders, [], f
+        )
+        a.makeConnection(b)
+        # one byte at a time, to stress the implementation.
+        for byte in iterbytes(requestBytes):
+            a.dataReceived(byte)
+
+        # Grab the request object and the stream completion callback.
+        stream = a.streams[1]
+        request = stream._request
+        cleanupCallback = a._streamCleanupCallbacks[1]
+
+        # Complete the connection immediately.
+        request.unregisterProducer()
+        request.finish()
+
+        # This should have completed the request.
+        self.assertTrue(request.finished)
+
+        # Check that the sending loop sends all the appropriate data.
+        def validate(streamID):
+            buffer = FrameBuffer()
+            buffer.receiveData(b.value())
+            frames = list(buffer)
+
+            self.assertEqual(len(frames), 3)
+
+            # Check that the stream is correctly terminated.
+            self.assertTrue('END_STREAM' in frames[-1].flags)
+
+            # Grab the data from the frames.
+            dataChunks = [
+                f.data for f in frames
+                if isinstance(f, hyperframe.frame.DataFrame)
+            ]
+            self.assertEqual(
+                dataChunks,
+                [b""],
+            )
+
+        return cleanupCallback.addCallback(validate)
+
+
+    def test_windowUpdateForCompleteStream(self):
+        """
+        WindowUpdate frames received after we've completed the stream are
+        safely handled.
+        """
+        # To test this with the data sending loop working the way it does, we
+        # need to send *no* body on the response. That's unusual, but fine.
+        f = FrameFactory()
+        b = StringTransport()
+        a = H2Connection()
+
+        # We use the DummyProducerHandler just because we can guarantee that it
+        # doesn't end up with a body.
+        a.requestFactory = DummyProducerHandler
+
+        # Send the request.
+        requestBytes = f.preamble()
+        requestBytes += buildRequestBytes(
+            self.getRequestHeaders, [], f
+        )
+        a.makeConnection(b)
+        # one byte at a time, to stress the implementation.
+        for byte in iterbytes(requestBytes):
+            a.dataReceived(byte)
+
+        # Grab the request object and the stream completion callback.
+        stream = a.streams[1]
+        request = stream._request
+        cleanupCallback = a._streamCleanupCallbacks[1]
+
+        # Complete the connection immediately.
+        request.unregisterProducer()
+        request.finish()
+
+        # This should have completed the request.
+        self.assertTrue(request.finished)
+
+        # Now open the flow control window a bit. This should cause no
+        # problems.
+        a.dataReceived(
+            f.buildWindowUpdateFrame(streamID=1, increment=50).serialize()
+        )
+
+        # Check that the sending loop sends all the appropriate data.
+        def validate(streamID):
+            buffer = FrameBuffer()
+            buffer.receiveData(b.value())
+            frames = list(buffer)
+
+            self.assertEqual(len(frames), 3)
+
+            # Check that the stream is correctly terminated.
+            self.assertTrue('END_STREAM' in frames[-1].flags)
+
+            # Grab the data from the frames.
+            dataChunks = [
+                f.data for f in frames
+                if isinstance(f, hyperframe.frame.DataFrame)
+            ]
+            self.assertEqual(
+                dataChunks,
+                [b""],
+            )
+
+        return cleanupCallback.addCallback(validate)
+
+
+    def test_producerUnblocked(self):
+        """
+        L{Request} objects that have registered producers that are not blocked
+        behind flow control do not have their producer notified.
+        """
+        f = FrameFactory()
+        b = StringTransport()
+        a = H2Connection()
+        a.requestFactory = DummyProducerHandler
+
+        # Shrink the window to 5 bytes, then send the request.
+        requestBytes = f.preamble()
+        requestBytes += f.buildSettingsFrame(
+            {h2.settings.INITIAL_WINDOW_SIZE: 5}
+        ).serialize()
+        requestBytes += buildRequestBytes(
+            self.getRequestHeaders, [], f
+        )
+        a.makeConnection(b)
+        # one byte at a time, to stress the implementation.
+        for byte in iterbytes(requestBytes):
+            a.dataReceived(byte)
+
+        # Grab the request object.
+        stream = a.streams[1]
+        request = stream._request
+
+        # Confirm that the stream believes the producer is producing.
+        self.assertTrue(stream._producerProducing)
+
+        # Write 4 bytes to the connection, leaving space in the window.
+        request.write(b"word")
+
+        # The producer should not have been paused.
+        self.assertTrue(stream._producerProducing)
+        self.assertEqual(request.producer.events, [])
+
+        # Open the flow control window by 5 bytes. This should not notify the
+        # producer.
+        a.dataReceived(
+            f.buildWindowUpdateFrame(streamID=1, increment=5).serialize()
+        )
+        self.assertTrue(stream._producerProducing)
+        self.assertEqual(request.producer.events, [])
+
+        # Open the window wide complete the request.
+        request.unregisterProducer()
+        request.finish()
+
+        # Check that the sending loop sends all the appropriate data.
+        def validate(streamID):
+            buffer = FrameBuffer()
+            buffer.receiveData(b.value())
+            frames = list(buffer)
+
+            # Check that the stream is correctly terminated.
+            self.assertTrue('END_STREAM' in frames[-1].flags)
+
+            # Grab the data from the frames.
+            dataChunks = [
+                f.data for f in frames
+                if isinstance(f, hyperframe.frame.DataFrame)
+            ]
+            self.assertEqual(
+                dataChunks,
+                [b"word", b""]
+            )
+
+        return a._streamCleanupCallbacks[1].addCallback(validate)
+
+
+    def test_unnecessaryWindowUpdate(self):
+        """
+        When a WindowUpdate frame is received for the whole connection but no
+        data is currently waiting, nothing exciting happens.
+        """
+        f = FrameFactory()
+        b = StringTransport()
+        a = H2Connection()
+        a.requestFactory = DummyHTTPHandler
+
+        # Send the request.
+        frames = buildRequestFrames(
+            self.postRequestHeaders, self.postRequestData, f
+        )
+        frames.insert(1, f.buildWindowUpdateFrame(streamID=0, increment=5))
+        requestBytes = f.preamble()
+        requestBytes += b''.join(f.serialize() for f in frames)
+        a.makeConnection(b)
+        # one byte at a time, to stress the implementation.
+        for byte in iterbytes(requestBytes):
+            a.dataReceived(byte)
+
+        # Give the sending loop a chance to catch up!
+        def validate(streamID):
+            buffer = FrameBuffer()
+            buffer.receiveData(b.value())
+            frames = list(buffer)
+
+            # Check that the stream is correctly terminated.
+            self.assertTrue('END_STREAM' in frames[-1].flags)
+
+            # Put the Data frames together to confirm we're all good.
+            actualResponseData = b''.join(
+                f.data for f in frames
+                if isinstance(f, hyperframe.frame.DataFrame)
+            )
+            self.assertEqual(self.postResponseData, actualResponseData)
+
+        return a._streamCleanupCallbacks[1].addCallback(validate)
