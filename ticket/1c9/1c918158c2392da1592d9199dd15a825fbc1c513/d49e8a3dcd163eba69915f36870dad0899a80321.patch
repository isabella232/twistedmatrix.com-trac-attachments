Index: twisted/python/dist.py
===================================================================
--- twisted/python/dist.py	(revision 46710)
+++ twisted/python/dist.py	(working copy)
@@ -78,7 +78,9 @@
     soap=['soappy'],
     serial=['pyserial'],
     osx=['pyobjc'],
-    windows=['pypiwin32']
+    windows=['pypiwin32'],
+    http2=['h2 >= 2.1.0, < 3.0',
+           'priority >= 1.1.0, < 2.0'],
 )
 
 _PLATFORM_INDEPENDENT = (
@@ -94,6 +96,7 @@
     'conch': _EXTRA_OPTIONS['conch'],
     'soap': _EXTRA_OPTIONS['soap'],
     'serial': _EXTRA_OPTIONS['serial'],
+    'http2': _EXTRA_OPTIONS['http2'],
     'all_non_platform': _PLATFORM_INDEPENDENT,
     'osx_platform': (
         _EXTRA_OPTIONS['osx'] + _PLATFORM_INDEPENDENT
Index: twisted/web/http2.py
===================================================================
--- twisted/web/http2.py	(revision 0)
+++ twisted/web/http2.py	(working copy)
@@ -0,0 +1,908 @@
+# -*- test-case-name: twisted.web.test.test_http2 -*-
+# Copyright (c) Twisted Matrix Laboratories.
+# See LICENSE for details.
+"""
+HTTP2 Implementation
+
+This is the basic server-side protocol implementation used by the Twisted
+Web server for HTTP2.  This functionality is intended to be combined with the
+HTTP/1.1 and HTTP/1.0 functionality in twisted.web.http to provide complete
+protocol support for HTTP-type protocols.
+
+Some function is currently missing here, including:
+
+- handling flow control, both remote and local
+- handling remote settings changes
+- deciding on suitable local settings values
+"""
+from __future__ import absolute_import
+
+import io
+
+from collections import deque
+
+from zope.interface import implementer
+
+import priority
+import h2.connection
+import h2.events
+import h2.exceptions
+
+from twisted.internet.defer import Deferred, inlineCallbacks
+from twisted.internet.interfaces import (
+    IProtocol, ITransport, IConsumer, IPushProducer
+)
+from twisted.internet.protocol import Protocol
+from twisted.internet.task import LoopingCall
+from twisted.protocols.tls import _PullToPush
+
+
+_END_STREAM_SENTINEL = object()
+
+
+
+@implementer(IProtocol, IPushProducer)
+class H2Connection(Protocol):
+    """
+    A class representing a single HTTP/2 connection.
+
+    This implementation of IProtocol works hand in hand with H2Stream. This is
+    because we have the requirement to register multiple producers for a single
+    HTTP/2 connection, one for each stream. The standard Twisted interfaces
+    don't really allow for this, so instead there's a custom interface between
+    the two objects that allows them to work hand-in-hand here.
+
+    @ivar conn: The HTTP/2 connection state machine.
+    @type conn: C{h2.connection.H2Connection}
+
+    @ivar streams: A mapping of stream IDs to L{H2Stream} objects, used to call
+        specific methods on streams when events occur.
+    @type streams: C{dict}, mapping C{int} stream IDs to L{H2Stream} objects.
+
+    @ivar priority: A HTTP/2 priority tree used to ensure that responses are
+        prioritised appropriately.
+    @type priority: L{priority.PriorityTree}
+
+    @ivar _consumerBlocked: A flag tracking whether or not the IConsumer that
+        is consuming this data has asked us to stop producing.
+    @type _consumerBlocked: C{bool}
+
+    @ivar _sendingDeferred: A deferred used to restart the data-sending loop
+        when more response data has been produced. Will not be present if there
+        is outstanding data still to send.
+    @type _consumerBlocked: A L{twisted.internet.defer.Deferred}, or C{None}
+
+    @ivar _outboundStreamQueues: A map of stream IDs to queues, used to store
+        data blocks that are yet to be sent on the connection. These are used
+        both to handle producers that do not respect IConsumer but also to
+        allow priority to multiplex data appropriately.
+    @type _outboundStreamQueues: A C{dict} mapping C{int} stream IDs to
+        C{collections.deque} queues, which contain either C{bytes} objects or
+        L{_END_STREAM_SENTINEL}.
+
+    @ivar _sender: A handle to the data-sending loop, allowing it to be
+        terminated if needed.
+    @type _sender: L{twisted.internet.task.LoopingCall}
+    """
+    factory = None
+    site = None
+
+
+    def __init__(self):
+        self.conn = h2.connection.H2Connection(client_side=False)
+        self.streams = {}
+
+        self.priority = priority.PriorityTree()
+        self._consumerBlocked = False
+        self._sendingDeferred = None
+        self._outboundStreamQueues = {}
+
+        # Start the data sending function.
+        self._sender = LoopingCall(self._sendPrioritisedData)
+        self._sender.start(interval=0)
+
+
+    # Implementation of IProtocol
+    def connectionMade(self):
+        """
+        Called by the reactor when a connection is received. May also be called
+        by the GenericHTTPChannel during upgrade to HTTP/2.
+        """
+        self.conn.initiate_connection()
+        self.transport.write(self.conn.data_to_send())
+
+
+    def dataReceived(self, data):
+        """
+        Called whenever a chunk of data is received from the transport.
+
+        @param data: The data received from the transport.
+        @type data: C{bytes}
+        """
+        try:
+            events = self.conn.receive_data(data)
+        except h2.exceptions.ProtocolError:
+            # A remote protocol error terminates the connection.
+            dataToSend = self.conn.data_to_send()
+            if dataToSend:
+                self.transport.write(dataToSend)
+
+            self.transport.loseConnection()
+            return
+
+        for event in events:
+            # TODO: Consider replacing with dictionary-dispatch.
+            if isinstance(event, h2.events.RequestReceived):
+                self._requestReceived(event)
+            elif isinstance(event, h2.events.DataReceived):
+                self._requestDataReceived(event)
+            elif isinstance(event, h2.events.StreamEnded):
+                self._requestEnded(event)
+            elif isinstance(event, h2.events.StreamReset):
+                self._requestAborted(event)
+            elif isinstance(event, h2.events.WindowUpdated):
+                self._handleWindowUpdate(event)
+            elif isinstance(event, h2.events.PriorityUpdated):
+                self._handlePriorityUpdate(event)
+            elif isinstance(event, h2.events.ConnectionTerminated):
+                self.transport.loseConnection()
+
+        dataToSend = self.conn.data_to_send()
+        if dataToSend:
+            self.transport.write(dataToSend)
+
+
+    def connectionLost(self, reason):
+        """
+        Called when the transport connection is lost.
+
+        Informs all outstanding response handlers that the connection has been
+        lost.
+        """
+        try:
+            self._sender.stop()
+        except Exception:
+            pass
+
+        for stream in self.streams.values():
+            stream.connectionLost(reason)
+
+        self.streams = {}
+
+
+    # Implementation of IPushProducer
+    #
+    # Here's how we handle IPushProducer. We have multiple outstanding
+    # H2Streams. Each of these exposes an IConsumer interface to the response
+    # handler that allows it to push data into the H2Stream. The H2Stream then
+    # writes the data into the H2Connection object.
+    #
+    # The H2Connection needs to manage these writes to account for:
+    #
+    # - flow control
+    # - priority
+    #
+    # We manage each of these in different ways.
+    #
+    # For flow control, we simply use the equivalent of the IPushProducer
+    # interface. We simply tell the H2Stream: "Hey, you can't send any data
+    # right now, sorry!". When that stream becomes unblocked, we free it up
+    # again. This allows the H2Stream to propagate this backpressure up the
+    # chain.
+    #
+    # For priority, we need to keep a backlog of data frames that we can send,
+    # and interleave them appropriately. This backlog is most sensibly kept in
+    # the H2Connection object itself. We keep one queue per stream, which is
+    # where the writes go, and then we have a loop that manages popping these
+    # streams off in priority order.
+    #
+    # Logically then, we go as follows:
+    #
+    # 1. Stream calls writeDataToStream(). This causes a DataFrame to be placed
+    #    on the queue for that stream. It also informs the priority
+    #    implementation that this stream is unblocked.
+    # 2. The _sendPrioritisedData() function spins in a tight loop. Each
+    #    iteration it asks the priority implementation which stream should send
+    #    next, and pops a data frame off that stream's queue. If, after sending
+    #    that frame, there is no data left on that stream's queue, the function
+    #    informs the priority implementation that the stream is blocked.
+    #
+    # If all streams are blocked, or if there are no outstanding streams, the
+    # _sendPrioritisedData function waits to be awoken when more data is ready
+    # to send.
+    #
+    # Note that all of this only applies to *data*. Headers and other control
+    # frames deliberately skip this processing as they are not subject to flow
+    # control or priority constraints.
+    def stopProducing(self):
+        """
+        Stop producing data.
+
+        This tells the H2Connection that its consumer has died, so it must stop
+        producing data for good.
+        """
+        self.connectionLost("stopProducing")
+
+
+    def pauseProducing(self):
+        """
+        Pause producing data.
+
+        Tells the H2Connection that it has produced too much data to process
+        for the time being, and to stop until resumeProducing() is called.
+        """
+        self._consumerBlocked = Deferred()
+
+
+    def resumeProducing(self):
+        """
+        Resume producing data.
+
+        This tells the H2Connection to re-add itself to the main loop and
+        produce more data for the consumer.
+        """
+        if self._consumerBlocked is not None:
+            self._consumerBlocked.callback(None)
+            self._consumerBlocked = None
+
+
+    @inlineCallbacks
+    def _sendPrioritisedData(self):
+        """
+        The data sending loop. Must be used within L{LoopingCall}.
+
+        This function sends data on streams according to the rules of HTTP/2
+        priority. It ensures that the data from each stream is interleved
+        according to the priority signalled by the client, making sure that the
+        connection is used with maximal efficiency.
+
+        This function will execute if data is available: if all data is
+        exhausted, the function will place a deferred onto the C{H2Connection}
+        object and wait until it is called to resume executing.
+        """
+        stream = None
+
+        while stream is None:
+            try:
+                stream = next(self.priority)
+            except priority.DeadlockError:
+                # All streams are currently blocked or not progressing. Wait
+                # until a new one becomes available.
+                assert self._sendingDeferred is None
+                self._sendingDeferred = Deferred()
+                yield self._sendingDeferred
+                self._sendingDeferred = None
+                continue
+
+        # Wait behind the transport.
+        if self._consumerBlocked is not None:
+            yield self._consumerBlocked
+
+        # TODO: Handle streams that currently have no data in them.
+        frameData = self._outboundStreamQueues[stream].popleft()
+        maxFrameSize = self.conn.max_outbound_frame_size
+
+        if frameData is _END_STREAM_SENTINEL:
+            self.conn.end_stream(stream)
+
+            # Doing some cleanup here. Only block the stream in priority, don't
+            self._requestDone(stream)
+        else:
+            # Respect the max frame size.
+            if len(frameData) > maxFrameSize:
+                excessData = frameData[maxFrameSize:]
+                frameData = frameData[:maxFrameSize]
+                self._outboundStreamQueues[stream].appendleft(excessData)
+
+            self.conn.send_data(stream, frameData)
+
+            # If there's no data left, this stream is now blocked.
+            if not self._outboundStreamQueues[stream]:
+                self.priority.block(stream)
+
+        self.transport.write(self.conn.data_to_send())
+
+
+    # Internal functions.
+    def _requestReceived(self, event):
+        """
+        Internal handler for when a request has been received.
+
+        @param event: The Hyper-h2 event that encodes information about the
+            received request.
+        @type event: L{h2.events.RequestReceived}
+        """
+        stream = H2Stream(
+            event.stream_id, self, event.headers, self.requestFactory
+        )
+        stream.site = self.site
+        stream.factory = self.factory
+        self.streams[event.stream_id] = stream
+
+        # Add the stream to the priority tree but immediately block it.
+        try:
+            self.priority.insert_stream(event.stream_id)
+        except priority.DuplicateStreamError:
+            # Stream already in the tree. This can happen if we received a
+            # PRIORITY frame before a HEADERS frame. Just move on: we set the
+            # stream up properly in _handlePriorityUpdate.
+            pass
+        else:
+            self.priority.block(event.stream_id)
+
+
+    def _requestDataReceived(self, event):
+        """
+        Internal handler for when a chunk of data is received for a given
+        request.
+
+        @param event: The Hyper-h2 event that encodes information about the
+            received data.
+        @type event: L{h2.events.DataReceived}
+        """
+        stream = self.streams[event.stream_id]
+        stream.receiveDataChunk(event.data, event.flow_controlled_length)
+
+
+    def _requestEnded(self, event):
+        """
+        Internal handler for when a request is complete, and we expect no
+        further data for that request.
+
+        @param event: The Hyper-h2 event that encodes information about the
+            completed stream.
+        @type event: L{h2.events.StreamEnded}
+        """
+        stream = self.streams[event.stream_id]
+        stream.requestComplete()
+
+
+    def _requestAborted(self, event):
+        """
+        Internal handler for when a request is aborted by a remote peer.
+
+        @param event: The Hyper-h2 event that encodes information about the
+            reset stream.
+        @type event: L{h2.events.StreamReset}
+        """
+        stream = self.streams[event.stream_id]
+        stream.connectionLost("Stream reset")
+        self._requestDone(event.stream_id)
+
+
+    def _handlePriorityUpdate(self, event):
+        """
+        Internal handler for when a stream priority is updated.
+
+        @param event: The Hyper-h2 event that encodes information about the
+            stream reprioritization.
+        @type event: L{h2.events.PriorityUpdate}
+        """
+        try:
+            self.priority.reprioritize(
+                stream_id=event.stream_id,
+                depends_on=event.depends_on or None,
+                weight=event.weight,
+                exclusive=event.exclusive,
+            )
+        except priority.MissingStreamError:
+            # A PRIORITY frame arrived before the HEADERS frame that would
+            # trigger us to insert the stream into the tree. That's fine: we
+            # can create the stream here and mark it as blocked.
+            self.priority.insert_stream(
+                stream_id=event.stream_id,
+                depends_on=event.depends_on or None,
+                weight=event.weight,
+                exclusive=event.exclusive,
+            )
+            self.priority.block(event.stream_id)
+
+
+    def writeHeaders(self, version, code, reason, headers, streamID):
+        """
+        Called by C{Request} objects to write a complete set of HTTP headers to
+        a stream.
+
+        @param version: The HTTP version in use. Unused in HTTP/2.
+        @type version: C{bytes}
+
+        @param code: The HTTP status code to write.
+        @type code: C{bytes}
+
+        @param reason: The HTTP reason phrase to write. Unused in HTTP/2.
+        @type reason: C{bytes}
+
+        @param headers: The headers to write to the stream.
+        @type headers: L{twisted.web.http_headers.Headers}
+
+        @param streamID: The ID of the stream to write the headers to.
+        @type streamID: C{int}
+        """
+        headers.insert(0, (b':status', code))
+        self.conn.send_headers(streamID, headers)
+        self.transport.write(self.conn.data_to_send())
+        self._outboundStreamQueues[streamID] = deque()
+
+
+    def writeDataToStream(self, streamID, data):
+        """
+        May be called by L{H2Stream} objects to write response data to a given
+        stream. Writes a single data frame.
+
+        @param streamID: The ID of the stream to write the data to.
+        @type streamID: C{int}
+
+        @param data: The data chunk to write to the stream.
+        @type data: C{bytes}
+        """
+        self._outboundStreamQueues[streamID].append(data)
+        self.priority.unblock(streamID)
+        if self._sendingDeferred is not None:
+            self._sendingDeferred.callback(streamID)
+            self._sendingDeferred = None
+
+
+    def endRequest(self, streamID):
+        """
+        Called by L{H2Stream} objects to signal completion of a response.
+
+        @param streamID: The ID of the stream to write the data to.
+        @type streamID: C{int}
+        """
+        self._outboundStreamQueues[streamID].append(_END_STREAM_SENTINEL)
+        self.priority.unblock(streamID)
+        if self._sendingDeferred is not None:
+            self._sendingDeferred.callback(streamID)
+            self._sendingDeferred = None
+
+
+    def _requestDone(self, streamID):
+        """
+        Called internally by the data sending loop to clean up state that was
+        being used for the stream. Called when the stream is complete.
+
+        @param streamID: The ID of the stream to clean up state for.
+        @type streamID: C{int}
+        """
+        # TODO: consider renaming?
+        del self._outboundStreamQueues[streamID]
+        self.priority.remove_stream(streamID)
+        del self.streams[streamID]
+
+
+    def remainingOutboundWindow(self, streamID):
+        """
+        Called by a C{H2Stream} object to determine how much room is left in
+        the send window for that stream. Allows C{H2Stream} objects to handle
+        flow control and buffering for their producers.
+
+        @param streamID: The ID of the stream whose flow control window we'll
+            check.
+        @type streamID: C{int}
+        """
+        # TODO: This involves a fair bit of looping and computation for
+        # something that is called a lot. Consider caching values somewhere.
+        windowSize = self.conn.local_flow_control_window(streamID)
+        sendQueue = self._outboundStreamQueues[streamID]
+        alreadyConsumed = sum(len(chunk) for chunk in sendQueue)
+
+        return windowSize - alreadyConsumed
+
+
+    def _handleWindowUpdate(self, event):
+        """
+        Manage flow control windows.
+
+        Streams that are blocked on flow control will register themselves with
+        the connection. This will fire deferreds that wake those streams up and
+        allow them to continue processing.
+
+        @param event: The Hyper-h2 event that encodes information about the
+            flow control window change.
+        @type event: L{h2.events.WindowUpdated}
+        """
+        streamID = event.stream_id
+
+        if streamID:
+            # Update applies only to a specific stream. If we don't have the
+            # stream, that's ok: just ignore it.
+            try:
+                self.streams[streamID].windowUpdated()
+            except KeyError:
+                pass
+        else:
+            # Update strictly applies to all streams.
+            for stream in self.streams.values():
+                stream.windowUpdated()
+
+
+    def getPeer(self):
+        """
+        @see L{ITransport.getPeer}
+        """
+        return self.transport.getPeer()
+
+
+    def getHost(self):
+        """
+        @see L{ITransport.getHost}
+        """
+        return self.transport.getHost()
+
+
+    def openStreamWindow(self, streamID, increment):
+        """
+        Open the stream window by a given increment.
+
+        @param streamID: The ID of the stream whose window needs to be opened.
+        @type streamID: C{int}
+
+        @param increment: The amount by which the stream window must be
+        incremented.
+        @type increment: C{int}
+        """
+        # TODO: Consider whether we want some kind of consolidating logic here.
+        self.conn.increment_flow_control_window(increment, stream_id=streamID)
+        self.conn.increment_flow_control_window(increment, stream_id=None)
+        self.transport.write(self.conn.data_to_send())
+
+
+
+@implementer(ITransport, IConsumer, IPushProducer)
+class H2Stream(object):
+    """
+    A class representing a single HTTP/2 stream.
+
+    This class works hand-in-hand with H2Connection. It acts to provide an
+    implementation of ITransport, IConsumer, and IProducer that work for a
+    single HTTP/2 connection, while tightly cleaving to the interface provided
+    by those interfaces. It does this by having a tight coupling to
+    H2Connection, which allows associating many of the functions of ITransport,
+    IConsumer, and IProducer to objects on a stream-specific level.
+
+    @ivar streamID: The numerical stream ID that this object corresponds to.
+    @type streamID: C{int}
+
+    @ivar producing: Whether this stream is currently allowed to produce data
+        to its consumer.
+    @type producing: C{bool}
+
+    @ivar command: The HTTP verb used on the request.
+    @type command: C{unicode}
+
+    @ivar path: The HTTP path used on the request.
+    @type path: C{unicode}
+
+    @ivar producer: The object producing the response, if any.
+    @type producer: L{IProducer}
+
+    @ivar _producerProducing: Whether the producer stored in producer is
+        currently producing data.
+    @type _producerProducing: C{bool}
+
+    @ivar _inboundDataBuffer: Any data that has been received from the network
+        but has not yet been received by the consumer.
+    @type _inboundDataBuffer: A L{collections.deque} containing C{bytes}
+
+    @ivar _conn: A reference to the connection this stream belongs to.
+    @type _conn: L{H2Connection}
+
+    @ivar _request: A request object that this stream corresponds to.
+    @type _request: L{twisted.web.iweb.IRequest}
+
+    @ivar _buffer: A buffer containing data produced by the producer that could
+        not be sent on the network at this time.
+    @type _buffer: L{io.BytesIO}
+    """
+    def __init__(self, streamID, connection, headers, requestFactory):
+        self.streamID = streamID
+        self.producing = False
+        self.command = None
+        self.path = None
+        self.producer = None
+        self._producerProducing = False
+        self._inboundDataBuffer = deque()
+        self._conn = connection
+        self._request = requestFactory(self, queued=False)
+        self._buffer = io.BytesIO()
+
+        self._convertHeaders(headers)
+
+    def _convertHeaders(self, headers):
+        """
+        This method converts the HTTP/2 header set into something that looks
+        like HTTP/1.1. In particular, it strips the 'special' headers and adds
+        a Host: header.
+
+        @param headers: The HTTP/2 header set.
+        @type headers: A C{list} of C{tuple}s of header name and header value,
+            both as C{unicode}.
+        """
+        gotLength = False
+
+        for header in headers:
+            if not header[0].startswith(b':'):
+                gotLength = (
+                    _addHeaderToRequest(self._request, header) or gotLength
+                )
+            elif header[0] == u':method':
+                self.command = header[1].encode('utf-8')
+            elif header[0] == u':path':
+                self.path = header[1].encode('utf-8')
+            elif header[0] == u':authority':
+                # This is essentially the Host: header from HTTP/1.1
+                _addHeaderToRequest(self._request, (u'host', header[1]))
+            else:
+                # There are only 4 acceptable special headers for requests.
+                if not header[0] == u':scheme':
+                    raise RuntimeError(
+                        "Unexpected special header %r" % header[0]
+                    )
+
+        if not gotLength:
+            self._request.gotLength(None)
+
+        self._request.parseCookies()
+
+
+    def receiveDataChunk(self, data, flow_controlled_length):
+        """
+        Called when the connection has received a chunk of data from the
+        underlying transport. If the stream has been registered with a
+        consumer, and is currently able to push data, immediately passes it
+        through. Otherwise, buffers the chunk until we can start producing.
+
+        @param data: The chunk of data that was received.
+        @type data: C{bytes}
+
+        @param flow_controlled_length: The total flow controlled length of this
+            chunk, which is used when we want to re-open the window. May be
+            different to C{len(data)}.
+        @type flow_controlled_length: C{int}
+        """
+        if not self.producing:
+            # Buffer data.
+            self._inboundDataBuffer.append((data, flow_controlled_length))
+        else:
+            self._request.handleContentChunk(data)
+            self._conn.openStreamWindow(self.streamID, flow_controlled_length)
+
+
+    def requestComplete(self):
+        """
+        Called by the L{H2Connection} when the all data for a request has been
+        received. Currently, with the legacy Request object, just calls
+        requestReceived.
+        """
+        self._request.requestReceived(self.command, self.path, b'HTTP/2')
+
+
+    def connectionLost(self, reason):
+        """
+        Called by the L{H2Connection} when a connection is lost or a stream is
+        reset.
+
+        @param reason: The reason the connection was lost.
+        @type reason: C{str}
+        """
+        self._request.connectionLost(reason)
+
+
+    def windowUpdated(self):
+        """
+        Called by the L{H2Connection} when this stream's flow control window
+        has been opened.
+        """
+        # If we're not blocked on flow control, we don't care.
+        if self.producer and self._producerProducing:
+            return
+
+        # We check whether the stream's flow control window is actually above
+        # 0, and then, if it is, send what we can of our buffered data. Then,
+        # if a producer is registered and we still have space in the window, we
+        # unblock it.
+        remainingWindow = self._conn.remainingOutboundWindow(self.streamID)
+        if not remainingWindow > 0:
+            return
+
+        # Empty the buffer and send what we can.
+        # TODO: Try to preserve the buffer here: we do a lot of copies.
+        data = self._buffer.getvalue()
+        dataToSend = data[:remainingWindow]
+        excessData = data[remainingWindow:]
+        self._conn.writeDataToStream(self.streamID, dataToSend)
+
+        # Create a new buffer: we exhausted the last one with getvalue().
+        self._buffer = io.BytesIO(excessData)
+
+        # If the producer is blocked and we still have room, unblock it.
+        if ((remainingWindow - len(dataToSend)) > 0) and (self.producer):
+            # Still space in the window! We can start producing.
+            self.producer._producerProducing = True
+            self.producer.resumeProducing()
+
+
+    def writeHeaders(self, version, code, reason, headers):
+        """
+        Called by the consumer to write headers to the stream.
+
+        @param version: The HTTP version.
+        @type version: C{str}
+
+        @param code: The status code.
+        @type code: C{int}
+
+        @param reason: The reason phrase. Ignored in HTTP/2.
+        @type reason: C{str}
+
+        @param headers: The HTTP response headers.
+        @type: Any iterable of two-tuples of C{bytes}, representing header
+            names and header values.
+        """
+        self._conn.writeHeaders(version, code, reason, headers, self.streamID)
+
+
+    def endRequest(self):
+        """
+        Called by the consumer when they've finished writing data.
+        """
+        self._conn.endRequest(self.streamID)
+
+
+    def requestDone(self, request):
+        """
+        Called by a consumer to clean up whatever permanent state is in use.
+        This is a no-op.
+
+        @param request: The request calling the method.
+        @type request: L{twisted.web.iweb.IRequest}
+        """
+        pass
+
+
+    # Implementation: ITransport
+    def write(self, data):
+        """
+        Write a single chunk of data into a data frame.
+
+        @param data: The data chunk to send.
+        @type data: C{bytes}
+        """
+        remainingWindow = self._conn.remainingOutboundWindow(self.streamID)
+
+        if remainingWindow - len(data) > 0:
+            # Best-case, write data immediately.
+            self._conn.writeDataToStream(self.streamID, data)
+            return
+
+        if remainingWindow > 0:
+            # We have some room in flow control, but must then buffer.
+            toWrite = data[:remainingWindow]
+            self._conn.writeDataToStream(self.streamID, toWrite)
+            data = data[remainingWindow:]
+
+        # We buffer what's left, then instruct the producer to pause.
+        self._buffer.write(data)
+        if self.producer is not None:
+            self.producer.pauseProducing()
+            self._producerProducing = False
+
+
+    def writeSequence(self, iovec):
+        """
+        Write a sequence of chunks of data into data frames.
+
+        @param iovec: A sequence of chunks to send.
+        @type iovec: An iterable of C{bytes} chunks.
+        """
+        for chunk in iovec:
+            self.write(chunk)
+
+
+    def loseConnection(self):
+        """
+        Close the connection after writing all pending data.
+        """
+        # TODO: How to signal early termination?
+        self._conn.endRequest(self.streamID)
+
+
+    def getPeer(self):
+        """
+        Get information about the peer.
+        """
+        self._conn.getPeer()
+
+
+    def getHost(self):
+        """
+        Similar to getPeer, but for this side of the connection.
+        """
+        self._conn.getHost()
+
+
+    # Implementation: IConsumer
+    def registerProducer(self, producer, streaming):
+        """
+        @see L{IConsumer.registerProducer}
+        """
+        if self.producer:
+            raise ValueError(
+                "registering producer %s before previous one (%s) was "
+                "unregistered" % (producer, self.producer))
+
+        if not streaming:
+            producer = _PullToPush(producer, self)
+            producer.startStreaming()
+
+        self.producer = producer
+        self._producerProducing = True
+
+
+    def unregisterProducer(self):
+        """
+        @see L{IConsumer.unregisterProducer}
+        """
+        # When the producer is unregistered, we're done.
+        self.producer = None
+        self._producerProducing = False
+        self.hasStreamingProducer = None
+
+        # TODO: When is this an error case?
+        #self.loseConnection()
+
+
+    # Implementation: IPushProducer
+    def stopProducing(self):
+        """
+        @see L{IProducer.stopProducing}
+        """
+        self.producing = False
+        # TODO: How to signal abnormal termination?
+        self.loseConnection()
+
+
+    def pauseProducing(self):
+        """
+        @see L{IPushProducer.pauseProducing}
+        """
+        self.producing = False
+
+
+    def resumeProducing(self):
+        """
+        @see L{IPushProducer.resumeProducing}
+        """
+        self.producing = True
+        consumedLength = 0
+
+        while self.producing and self._inboundDataBuffer:
+            # Allow for pauseProducing to be called in response to a call to
+            # resumeProducing.
+            chunk, flow_controlled_length = self._inboundDataBuffer.popleft()
+            consumedLength += flow_controlled_length
+            self._request.handleContentChunk(chunk)
+
+        self._conn.openStreamWindow(self.streamID, consumedLength)
+
+
+
+def _addHeaderToRequest(request, header):
+    """
+    Add a header tuple to a request header object.
+    """
+    requestHeaders = request.requestHeaders
+    name, value = header
+    name, value = name.encode('utf-8'), value.encode('utf-8')
+    values = requestHeaders.getRawHeaders(name)
+
+    if values is not None:
+        values.append(value)
+    else:
+        requestHeaders.setRawHeaders(name, [value])
+
+    if name == b'content-length':
+        request.gotLength(int(value))
+        return True
+
+    return False
