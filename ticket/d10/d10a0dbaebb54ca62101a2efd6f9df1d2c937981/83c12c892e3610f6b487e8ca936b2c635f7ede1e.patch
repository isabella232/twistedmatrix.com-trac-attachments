diff --git a/twisted/web/http.py b/twisted/web/http.py
index 3f7974f..85c414d 100644
--- a/twisted/web/http.py
+++ b/twisted/web/http.py
@@ -91,6 +91,7 @@ from zope.interface import implementer, provider
 # twisted imports
 from twisted.python.compat import (
     _PY3, unicode, intToBytes, networkString, nativeString)
+from twisted.python.constants import NamedConstant, Names
 from twisted.python.deprecate import deprecated
 from twisted.python import log
 from twisted.python.versions import Version
@@ -568,6 +569,16 @@ class Request:
         which this request was received is closed and which is C{True} after
         that.
     @type _disconnected: C{bool}
+
+    @ivar _queuedHeaders: A L{tuple} of items that would normally be passed to
+        L{HTTPChannel.writeHeaders}. Used when the response is queued to store
+        the eventual headers.
+    @type _queuedHeaders: A L{tuple} of HTTP version (:{bytes}), status code
+        (L{int}), reason phrase (L{bytes}), and headers (L{list} of L{tuple}s
+        of C{(bytes, bytes)}.
+
+    @ivar _send100: Whether to send a 100-Continue response when unqueued.
+    @type _send100: L{bool}
     """
     producer = None
     finished = 0
@@ -586,6 +597,8 @@ class Request:
     content = None
     _forceSSL = 0
     _disconnected = False
+    _queuedHeaders = None
+    _send100 = False
 
     def __init__(self, channel, queued):
         """
@@ -603,8 +616,10 @@ class Request:
 
         if queued:
             self.transport = StringTransport()
+            self._writer = self.transport
         else:
             self.transport = self.channel.transport
+            self._writer = self.channel
 
 
     def _cleanup(self):
@@ -616,6 +631,7 @@ class Request:
             self.unregisterProducer()
         self.channel.requestDone(self)
         del self.channel
+        del self._writer
         try:
             self.content.close()
         except OSError:
@@ -644,12 +660,20 @@ class Request:
         # set transport to real one and send any buffer data
         data = self.transport.getvalue()
         self.transport = self.channel.transport
+        self._writer = self.channel
+        if self._send100:
+            self._writer._send100Continue()
+        if self._queuedHeaders:
+            self._writer.writeHeaders(*self._queuedHeaders)
+            self._queuedHeaders = None
         if data:
-            self.transport.write(data)
+            self._writer.write(data)
 
         # if we have producer, register it with transport
         if (self.producer is not None) and not self.finished:
-            self.transport.registerProducer(self.producer, self.streamingProducer)
+            self._writer.registerProducer(
+                self.producer, self.streamingProducer
+            )
 
         # if we're finished, clean up
         if self.finished:
@@ -733,8 +757,8 @@ class Request:
 
         # cache the client and server information, we'll need this later to be
         # serialized and sent with the request so CGIs will work remotely
-        self.client = self.channel.transport.getPeer()
-        self.host = self.channel.transport.getHost()
+        self.client = self.channel.getPeer()
+        self.host = self.channel.getHost()
 
         # Argument processing
         args = self.args
@@ -761,7 +785,7 @@ class Request:
                         self.args.update(cgiArgs)
                 except:
                     # It was a bad request.
-                    _respondToBadRequestAndDisconnect(self.channel.transport)
+                    self.channel._respondToBadRequestAndDisconnect()
                     return
             self.content.seek(0, 0)
 
@@ -811,14 +835,14 @@ class Request:
             if streaming:
                 producer.pauseProducing()
         else:
-            self.transport.registerProducer(producer, streaming)
+            self.channel.registerProducer(producer, streaming)
 
     def unregisterProducer(self):
         """
         Unregister the producer.
         """
         if not self.queued:
-            self.transport.unregisterProducer()
+            self.channel.unregisterProducer()
         self.producer = None
 
 
@@ -880,7 +904,7 @@ class Request:
 
         if self.chunked:
             # write last chunk and closing CRLF
-            self.transport.write(b"0\r\n\r\n")
+            self._writer.write(b"0\r\n\r\n")
 
         # log request
         if hasattr(self.channel, "factory"):
@@ -905,11 +929,10 @@ class Request:
         if not self.startedWriting:
             self.startedWriting = 1
             version = self.clientproto
-            l = []
-            l.append(
-                version + b" " +
-                intToBytes(self.code) + b" " +
-                self.code_message + b"\r\n")
+            code = intToBytes(self.code)
+            reason = self.code_message
+
+            headers = []
 
             # if we don't have a content length, we send data in
             # chunked mode, so that we can support pipelining in
@@ -917,7 +940,7 @@ class Request:
             if ((version == b"HTTP/1.1") and
                 (self.responseHeaders.getRawHeaders(b'content-length') is None) and
                 self.method != b"HEAD" and self.code not in NO_BODY_CODES):
-                l.append(b'Transfer-Encoding: chunked\r\n')
+                headers.append((b'Transfer-Encoding', b'chunked'))
                 self.chunked = 1
 
             if self.lastModified is not None:
@@ -941,14 +964,15 @@ class Request:
                             category=DeprecationWarning, stacklevel=2)
                         # Backward compatible cast for non-bytes values
                         value = networkString('%s' % (value,))
-                    l.extend([name, b": ", value, b"\r\n"])
+                    headers.append((name, value))
 
             for cookie in self.cookies:
-                l.append(b'Set-Cookie: ' + cookie + b'\r\n')
+                headers.append((b'Set-Cookie', cookie))
 
-            l.append(b"\r\n")
-
-            self.transport.writeSequence(l)
+            if self.queued:
+                self._queuedHeaders = (version, code, reason, headers)
+            else:
+                self.channel.writeHeaders(version, code, reason, headers)
 
             # if this is a "HEAD" request, we shouldn't return any data
             if self.method == b"HEAD":
@@ -963,9 +987,9 @@ class Request:
         self.sentLength = self.sentLength + len(data)
         if data:
             if self.chunked:
-                self.transport.writeSequence(toChunk(data))
+                self._writer.writeSequence(toChunk(data))
             else:
-                self.transport.write(data)
+                self._writer.write(data)
 
     def addCookie(self, k, v, expires=None, domain=None, path=None,
                   max_age=None, comment=None, secure=None, httpOnly=False):
@@ -1249,6 +1273,7 @@ class Request:
         else:
             return None
 
+
     def isSecure(self):
         """
         Return True if this request is using a secure transport.
@@ -1264,11 +1289,12 @@ class Request:
         """
         if self._forceSSL:
             return True
-        transport = getattr(getattr(self, 'channel', None), 'transport', None)
-        if interfaces.ISSLTransport(transport, None) is not None:
-            return True
+        channel = getattr(self, 'channel', None)
+        if channel:
+            return channel._isSecure()
         return False
 
+
     def _authorize(self):
         # Authorization, (mostly) per the RFC
         try:
@@ -1346,6 +1372,24 @@ class Request:
             d.errback(reason)
         self.notifications = []
 
+
+    def loseConnection(self):
+        """
+        Pass the loseConnection through to the underlying channel.
+        """
+        self.channel.loseConnection()
+
+
+    def _send100Continue(self):
+        """
+        Sends a "100 Continue" status code, where 100 Continue is supported.
+        """
+        if not self.queued:
+            self.channel._send100Continue()
+        else:
+            self._send100 = True
+
+
 Request.getClient = deprecated(
     Version("Twisted", 15, 0, 0),
     "Twisted Names to resolve hostnames")(Request.getClient)
@@ -1585,6 +1629,25 @@ class _ChunkedTransferDecoder(object):
 
 
 
+class _ChannelSendState(Names):
+    """
+    Defines a collection of states that indicate what portion of a HTTP
+    response has already been sent on L{HTTPChannel}. Used to enforce that
+    callers of methods on the L{HTTPChannel} are calling them at the
+    appropriate times and to prevent callers from sending invalid HTTP
+    responses.
+
+    The state of the channel send state goes from C{IDLE} (the previous
+    response is complete), optionally to C{SENT_100_CONTINUE}, and then to
+    C{SENT_HEADERS} When the response is complete, the state is reset to
+    C{IDLE}.
+    """
+    IDLE = NamedConstant()
+    SENT_100_CONTINUE = NamedConstant()
+    SENT_HEADERS = NamedConstant()
+
+
+
 class HTTPChannel(basic.LineReceiver, policies.TimeoutMixin):
     """
     A receiver for HTTP requests.
@@ -1627,6 +1690,7 @@ class HTTPChannel(basic.LineReceiver, policies.TimeoutMixin):
         # the request queue
         self.requests = []
         self._transferDecoder = None
+        self._sendState = _ChannelSendState.IDLE
 
 
     def connectionMade(self):
@@ -1642,7 +1706,7 @@ class HTTPChannel(basic.LineReceiver, policies.TimeoutMixin):
 
         self._receivedHeaderSize += len(line)
         if (self._receivedHeaderSize > self.totalHeadersSize):
-            _respondToBadRequestAndDisconnect(self.transport)
+            self._respondToBadRequestAndDisconnect()
             return
 
         if self.__first_line:
@@ -1666,13 +1730,13 @@ class HTTPChannel(basic.LineReceiver, policies.TimeoutMixin):
 
             parts = line.split()
             if len(parts) != 3:
-                _respondToBadRequestAndDisconnect(self.transport)
+                self._respondToBadRequestAndDisconnect()
                 return
             command, request, version = parts
             try:
                 command.decode("ascii")
             except UnicodeDecodeError:
-                _respondToBadRequestAndDisconnect(self.transport)
+                self._respondToBadRequestAndDisconnect()
                 return
 
             self._command = command
@@ -1717,7 +1781,7 @@ class HTTPChannel(basic.LineReceiver, policies.TimeoutMixin):
         try:
             header, data = line.split(b':', 1)
         except ValueError:
-            _respondToBadRequestAndDisconnect(self.transport)
+            self._respondToBadRequestAndDisconnect()
             return
 
         header = header.lower()
@@ -1726,7 +1790,7 @@ class HTTPChannel(basic.LineReceiver, policies.TimeoutMixin):
             try:
                 self.length = int(data)
             except ValueError:
-                _respondToBadRequestAndDisconnect(self.transport)
+                self._respondToBadRequestAndDisconnect()
                 self.length = None
                 return
             self._transferDecoder = _IdentityTransferDecoder(
@@ -1746,7 +1810,7 @@ class HTTPChannel(basic.LineReceiver, policies.TimeoutMixin):
 
         self._receivedHeaderCount += 1
         if self._receivedHeaderCount > self.maxHeaders:
-            _respondToBadRequestAndDisconnect(self.transport)
+            self._respondToBadRequestAndDisconnect()
             return
 
 
@@ -1777,7 +1841,7 @@ class HTTPChannel(basic.LineReceiver, policies.TimeoutMixin):
         try:
             self._transferDecoder.dataReceived(data)
         except _MalformedChunkedDataError:
-            _respondToBadRequestAndDisconnect(self.transport)
+            self._respondToBadRequestAndDisconnect()
 
 
     def allHeadersReceived(self):
@@ -1790,7 +1854,7 @@ class HTTPChannel(basic.LineReceiver, policies.TimeoutMixin):
         expectContinue = req.requestHeaders.getRawHeaders(b'expect')
         if (expectContinue and expectContinue[0].lower() == b'100-continue' and
             self._version == b'HTTP/1.1'):
-            req.transport.write(b"HTTP/1.1 100 Continue\r\n\r\n")
+            req._send100Continue()
 
 
     def checkPersistence(self, request, version):
@@ -1845,6 +1909,8 @@ class HTTPChannel(basic.LineReceiver, policies.TimeoutMixin):
         del self.requests[0]
 
         if self.persistent:
+            self._sendState = _ChannelSendState.IDLE
+
             # notify next request it can start writing
             if self.requests:
                 self.requests[0].noLongerQueued()
@@ -1864,20 +1930,168 @@ class HTTPChannel(basic.LineReceiver, policies.TimeoutMixin):
             request.connectionLost(reason)
 
 
+    def writeHeaders(self, version, code, reason, headers):
+        """
+        Called by L{Request} objects to write a complete set of HTTP headers to
+        a transport.
 
-def _respondToBadRequestAndDisconnect(transport):
-    """
-    This is a quick and dirty way of responding to bad requests.
+        @param version: The HTTP version in use.
+        @type version: L{bytes}
 
-    As described by HTTP standard we should be patient and accept the
-    whole request from the client before sending a polite bad request
-    response, even in the case when clients send tons of data.
+        @param code: The HTTP status code to write.
+        @type code: L{bytes}
 
-    @param transport: Transport handling connection to the client.
-    @type transport: L{interfaces.ITransport}
-    """
-    transport.write(b"HTTP/1.1 400 Bad Request\r\n\r\n")
-    transport.loseConnection()
+        @param reason: The HTTP reason phrase to write.
+        @type reason: L{bytes}
+
+        @param headers: The headers to write to the transport.
+        @type headers: L{twisted.web.http_headers.Headers}
+        """
+        assert self._sendState in (
+            _ChannelSendState.IDLE, _ChannelSendState.SENT_100_CONTINUE
+        )
+        responseLine = version + b" " + code + b" " + reason + b"\r\n"
+        headerSequence = [responseLine]
+        headerSequence.extend(
+            name + b': ' + value + b"\r\n" for name, value in headers
+        )
+        headerSequence.append(b"\r\n")
+        self.transport.writeSequence(headerSequence)
+        self._sendState = _ChannelSendState.SENT_HEADERS
+
+
+    def registerProducer(self, producer, streaming):
+        """
+        Register to receive data from a producer.
+
+        This sets self to be a consumer for a producer.  When this object runs
+        out of data (as when a send(2) call on a socket succeeds in moving the
+        last data from a userspace buffer into a kernelspace buffer), it will
+        ask the producer to resumeProducing().
+
+        For L{IPullProducer} providers, C{resumeProducing} will be called once
+        each time data is required.
+
+        For L{IPushProducer} providers, C{pauseProducing} will be called
+        whenever the write buffer fills up and C{resumeProducing} will only be
+        called when it empties.
+
+        @type producer: L{IProducer} provider
+        @param producer: The L{IProducer} that will be producing data.
+
+        @type streaming: L{bool}
+        @param streaming: C{True} if C{producer} provides L{IPushProducer},
+        C{False} if C{producer} provides L{IPullProducer}.
+
+        @raise RuntimeError: If a producer is already registered.
+
+        @return: C{None}
+        """
+        return self.transport.registerProducer(producer, streaming)
+
+
+    def unregisterProducer(self):
+        """
+        Stop consuming data from a producer, without disconnecting.
+
+        @return: C{None}
+        """
+        return self.transport.unregisterProducer()
+
+
+    def write(self, data):
+        """
+        Called by L{Request} objects to write response data.
+
+        @param data: The data chunk to write to the stream.
+        @type data: L{bytes}
+
+        @return: C{None}
+        """
+        assert self._sendState == _ChannelSendState.SENT_HEADERS
+        self.transport.write(data)
+
+
+    def writeSequence(self, iovec):
+        """
+        Write a list of strings to the HTTP response.
+
+        @param iovec: A list of byte strings to write to the stream.
+        @type data: L{list} of L{bytes}
+
+        @return: C{None}
+        """
+        assert self._sendState == _ChannelSendState.SENT_HEADERS
+        self.transport.writeSequence(iovec)
+
+
+    def getPeer(self):
+        """
+        Get the remote address of this connection.
+
+        @return: An L{IAddress} provider.
+        """
+        return self.transport.getPeer()
+
+
+    def getHost(self):
+        """
+        Get the local address of this connection.
+
+        @return: An L{IAddress} provider.
+        """
+        return self.transport.getHost()
+
+
+    def loseConnection(self):
+        """
+        Closes the connection. Will write any data that is pending to be sent
+        on the network, but if this response has not yet been written to the
+        network will not write anything.
+
+        @return: C{None}
+        """
+        # TODO: Does this need to be smarter, particularly about queued
+        # responses?
+        return self.transport.loseConnection()
+
+
+    def _isSecure(self):
+        """
+        Returns C{True} if this channel is using a secure transport.
+
+        @returns: C{True} if this channel is secure.
+        @rtype: L{bool}
+        """
+        # A channel is secure if its transport is ISSLTransport.
+        return interfaces.ISSLTransport(self.transport, None) is not None
+
+
+    def _send100Continue(self):
+        """
+        Sends a 100 Continue response, used to signal to clients that further
+        processing will be performed.
+        """
+        assert self._sendState == _ChannelSendState.IDLE
+        self.transport.write(b"HTTP/1.1 100 Continue\r\n\r\n")
+        self._sendState = _ChannelSendState.SENT_100_CONTINUE
+
+
+    def _respondToBadRequestAndDisconnect(self):
+        """
+        This is a quick and dirty way of responding to bad requests.
+
+        As described by HTTP standard we should be patient and accept the
+        whole request from the client before sending a polite bad request
+        response, even in the case when clients send tons of data.
+        """
+        # FIXME: There is nothing in this method to ensure that the response it
+        # sends is not intermingled with some other response body being written
+        # at the same time. Clearly this isn't the end of the world: the method
+        # has been arund a little while. Still, this should probably be
+        # refactored.
+        self.transport.write(b"HTTP/1.1 400 Bad Request\r\n\r\n")
+        self.transport.loseConnection()
 
 
 
diff --git a/twisted/web/test/requesthelper.py b/twisted/web/test/requesthelper.py
index 9f18785..b473b22 100644
--- a/twisted/web/test/requesthelper.py
+++ b/twisted/web/test/requesthelper.py
@@ -53,6 +53,9 @@ class DummyChannel:
         def registerProducer(self, producer, streaming):
             self.producers.append((producer, streaming))
 
+        def unregisterProducer(self):
+            pass
+
         def loseConnection(self):
             self.disconnected = True
 
@@ -71,6 +74,61 @@ class DummyChannel:
         pass
 
 
+    def writeHeaders(self, version, code, reason, headers):
+        response_line = version + b" " + code + b" " + reason + b"\r\n"
+        headerSequence = [response_line]
+        headerSequence.extend(
+            name + b': ' + value + b"\r\n" for name, value in headers
+        )
+        headerSequence.append(b"\r\n")
+        self.transport.writeSequence(headerSequence)
+
+
+    def getPeer(self):
+        return self.transport.getPeer()
+
+
+    def getHost(self):
+        return self.transport.getHost()
+
+
+    def registerProducer(self, producer, streaming):
+        self.transport.registerProducer(producer, streaming)
+
+
+    def unregisterProducer(self):
+        self.transport.unregisterProducer()
+
+
+    def write(self, data):
+        self.transport.write(data)
+
+
+    def writeSequence(self, iovec):
+        self.transport.writeSequence(iovec)
+
+
+    def loseConnection(self):
+        self.transport.loseConnection()
+
+
+    def endRequest(self):
+        pass
+
+
+    @property
+    def producers(self):
+        return self.transport.producers
+
+
+    def _send100Continue(self):
+        self.transport.write(b"HTTP/1.1 100 Continue\r\n\r\n")
+
+
+    def _isSecure(self):
+        return ISSLTransport(self.transport, None) is not None
+
+
 
 class DummyRequest(object):
     """
diff --git a/twisted/web/test/test_http.py b/twisted/web/test/test_http.py
index 3918117..7e80ec7 100644
--- a/twisted/web/test/test_http.py
+++ b/twisted/web/test/test_http.py
@@ -338,6 +338,105 @@ class GenericHTTPChannelTests(unittest.TestCase):
 
 
 
+class ResponseWriteOrderingTests(unittest.TestCase):
+    requests = (
+        b"GET / HTTP/1.1\r\n"
+        b"Accept: text/html\r\n"
+        b"\r\n"
+        b"GET / HTTP/1.1\r\n"
+        b"\r\n")
+
+
+    def setUp(self):
+        self.transport = StringTransport()
+        self.channel = http.HTTPChannel()
+        self.channel.requestFactory = http.Request
+        self.channel.makeConnection(self.transport)
+        self.channel.dataReceived(self.requests)
+
+
+    def test_cannotWriteBeforeHeaders(self):
+        """
+        The L{HTTPChannel} forbids writes before headers are sent.
+        """
+        self.assertRaises(
+            AssertionError,
+            self.channel.write,
+            b"some response data",
+        )
+
+
+    def test_cannot100ContinueAfterHeaders(self):
+        """
+        The L{HTTPChannel} forbids sending 100 Continue after headers were
+        sent.
+        """
+        self.channel.writeHeaders(b"HTTP/1.1", b"200", b"OK", [])
+        self.assertRaises(
+            AssertionError,
+            self.channel._send100Continue,
+        )
+
+
+    def test_cannotSendHeadersTwice(self):
+        """
+        The L{HTTPChannel} forbids sending a header block twice.
+        """
+        self.channel.writeHeaders(b"HTTP/1.1", b"200", b"OK", [])
+        self.assertRaises(
+            AssertionError,
+            self.channel.writeHeaders,
+            b"HTTP/1.1",
+            b"200",
+            b"OK",
+            [],
+        )
+
+
+    def test_completingRequestAllows100ContinueAfterHeaders(self):
+        """
+        The L{HTTPChannel} allows a 100 Continue once a request is complete.
+        """
+        self.channel.writeHeaders(b"HTTP/1.1", b"200", b"OK", [])
+        self.channel.requestDone(self.channel.requests[0])
+        self.channel._send100Continue()
+
+        self.assertEqual(
+            self.transport.value(),
+            b"HTTP/1.1 200 OK\r\n\r\nHTTP/1.1 100 Continue\r\n\r\n",
+        )
+
+
+    def test_completingRequestAllowsNewHeaders(self):
+        """
+        The L{HTTPChannel} allows sending a new header block after headers are
+        complete.
+        """
+        self.channel.writeHeaders(b"HTTP/1.1", b"200", b"OK", [])
+        self.channel.requestDone(self.channel.requests[0])
+        self.channel.writeHeaders(b"HTTP/1.1", b"204", b"No Content", [])
+
+        self.assertEqual(
+            self.transport.value(),
+            b"HTTP/1.1 200 OK\r\n\r\nHTTP/1.1 204 No Content\r\n\r\n",
+        )
+
+
+    def test_canWriteAfterHeaders(self):
+        """
+        The L{HTTPChannel} allows writing data after headers.
+        """
+        headers = [(b'Content-Length', b'5')]
+        self.channel.writeHeaders(b"HTTP/1.1", b"200", b"OK", headers)
+        self.channel.write(b'hello')
+
+        self.assertEqual(
+            self.transport.value(),
+            b"HTTP/1.1 200 OK\r\nContent-Length: 5\r\n\r\nhello",
+        )
+
+
+
 class HTTPLoopbackTests(unittest.TestCase):
 
     expectedHeaders = {b'request': b'/foo/bar',
@@ -1742,8 +1841,10 @@ class RequestTests(unittest.TestCase, ResponseTestMixin):
         For an HTTP 1.0 request, L{http.Request.write} sends an HTTP 1.0
         Response-Line and whatever response headers are set.
         """
-        req = http.Request(DummyChannel(), False)
+        channel = DummyChannel()
         trans = StringTransport()
+        channel.transport = trans
+        req = http.Request(channel, False)
 
         req.transport = trans
 
@@ -1764,8 +1865,10 @@ class RequestTests(unittest.TestCase, ResponseTestMixin):
         L{http.Request.write} casts non-bytes header value to bytes
         transparently.
         """
-        req = http.Request(DummyChannel(), False)
+        channel = DummyChannel()
         trans = StringTransport()
+        channel.transport = trans
+        req = http.Request(channel, False)
 
         req.transport = trans
 
@@ -1796,8 +1899,10 @@ class RequestTests(unittest.TestCase, ResponseTestMixin):
         Response-Line, whatever response headers are set, and uses chunked
         encoding for the response body.
         """
-        req = http.Request(DummyChannel(), False)
+        channel = DummyChannel()
         trans = StringTransport()
+        channel.transport = trans
+        req = http.Request(channel, False)
 
         req.transport = trans
 
@@ -1821,8 +1926,10 @@ class RequestTests(unittest.TestCase, ResponseTestMixin):
         L{http.Request.write} sends an HTTP Response-Line, whatever response
         headers are set, and a last-modified header with that time.
         """
-        req = http.Request(DummyChannel(), False)
+        channel = DummyChannel()
         trans = StringTransport()
+        channel.transport = trans
+        req = http.Request(channel, False)
 
         req.transport = trans
 
@@ -2263,6 +2370,51 @@ class RequestTests(unittest.TestCase, ResponseTestMixin):
                       factory.logFile.getvalue())
 
 
+    def test_sendHeadersWhenUnqueued(self):
+        """
+        Unqueueing a L{Request} sends headers properly.
+        """
+        transport = StringTransport()
+        channel = DummyChannel()
+        channel.transport = transport
+        request = http.Request(channel, True)
+        request.gotLength(123)
+        request.requestReceived(b"GET", b"/", b"HTTP/1.1")
+        request.write(b'test data')
+
+        self.assertEqual(transport.value(), b'')
+
+        request.noLongerQueued()
+
+        self.assertEqual(
+            transport.value(),
+            b"HTTP/1.1 200 OK\r\nTransfer-Encoding: chunked\r\n\r\n9\r\n"
+            b"test data\r\n"
+        )
+
+
+    def test_send100ContinueWhenUnqueued(self):
+        """
+        Unqueueing a L{Request} sends any 100-Continue repsonse properly.
+        """
+        transport = StringTransport()
+        channel = DummyChannel()
+        channel.transport = transport
+        request = http.Request(channel, True)
+        request.gotLength(123)
+        request.requestReceived(b"GET", b"/", b"HTTP/1.1")
+        request._send100Continue()
+
+        self.assertEqual(transport.value(), b'')
+
+        request.noLongerQueued()
+
+        self.assertEqual(
+            transport.value(),
+            b"HTTP/1.1 100 Continue\r\n\r\n"
+        )
+
+
 
 class MultilineHeadersTests(unittest.TestCase):
     """
diff --git a/twisted/web/test/test_proxy.py b/twisted/web/test/test_proxy.py
index 68a99c7..759707e 100644
--- a/twisted/web/test/test_proxy.py
+++ b/twisted/web/test/test_proxy.py
@@ -123,6 +123,14 @@ class DummyChannel(object):
         self.lostReason = reason
 
 
+    def getPeer(self):
+        return self.transport.getPeer()
+
+
+    def getHost(self):
+        return self.transport.getHost()
+
+
 
 class ProxyClientTests(TestCase):
     """
diff --git a/twisted/web/test/test_web.py b/twisted/web/test/test_web.py
index 23eb86d..ad9cd00 100644
--- a/twisted/web/test/test_web.py
+++ b/twisted/web/test/test_web.py
@@ -866,7 +866,7 @@ class NewRenderTests(unittest.TestCase):
         resource = HeadlessResource()
         req = self._getReq(resource)
         req.requestReceived(b"HEAD", b"/newrender", b"HTTP/1.0")
-        headers, body = req.transport.getvalue().split(b'\r\n\r\n')
+        body = req.transport.getvalue()
         self.assertEqual(req.code, 200)
         self.assertEqual(body, b'')
 
@@ -887,7 +887,7 @@ class NewRenderTests(unittest.TestCase):
 
         request.requestReceived(b"GET", b"/newrender", b"HTTP/1.0")
 
-        headers, body = request.transport.getvalue().split(b'\r\n\r\n')
+        body = request.transport.getvalue()
         self.assertEqual(request.code, 500)
         expected = [
             '',
diff --git a/twisted/web/wsgi.py b/twisted/web/wsgi.py
index 3f30658..b55e829 100644
--- a/twisted/web/wsgi.py
+++ b/twisted/web/wsgi.py
@@ -506,7 +506,7 @@ class _WSGIResponse:
             def wsgiError(started, type, value, traceback):
                 err(Failure(value, type, traceback), "WSGI application error")
                 if started:
-                    self.request.transport.loseConnection()
+                    self.request.loseConnection()
                 else:
                     self.request.setResponseCode(INTERNAL_SERVER_ERROR)
                     self.request.finish()
